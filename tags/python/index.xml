<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on 中文文档</title>
    <link>https://richfan.site/tags/python/</link>
    <description>Recent content in python on 中文文档</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 22 Oct 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://richfan.site/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>9款最佳Python脚本：让工作自动化起来！</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/9%E6%AC%BE%E6%9C%80%E4%BD%B3python%E8%84%9A%E6%9C%AC%E8%AE%A9%E5%B7%A5%E4%BD%9C%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B5%B7%E6%9D%A5/</link>
      <pubDate>Sun, 22 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/9%E6%AC%BE%E6%9C%80%E4%BD%B3python%E8%84%9A%E6%9C%AC%E8%AE%A9%E5%B7%A5%E4%BD%9C%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B5%B7%E6%9D%A5/</guid>
      <description>一、自动化文件管理# 1.在目录中对文件进行排序# # Python脚本用于按文件扩展名对目录中的文件进行排序 import os from shutil import move def sort_files(directory_path): for filename in os.listdir(directory_path): if os.path.isfile(os.path.join(directory_path, filename)): file_extension = filename.split(&amp;#39;.&amp;#39;)[-1] destination_directory = os.path.join(directory_path, file_extension) if not os.path.exists(destination_directory): os.makedirs(destination_directory) move(os.path.join(directory_path, filename), os.path.join(destination_directory, filename) 这个Python脚本通过根据文件扩展名将文件分类到子目录中来整理目录中的文件。&#xA;它识别文件扩展名并将文件移动到相应的子目录中。这对于清理下载文件夹或为特定项目组织文件非常有用。&#xA;2.删除空文件# # 用Python脚本删除目录中的空文件夹 import os def remove_empty_folders(directory_path): for root, dirs, files in os.walk(directory_path, topdown=False): for folder in dirs: folder_path = os.path.join(root, folder) if not os.listdir(folder_path): os.rmdir(folder_path) 此Python脚本在指定目录中搜索并删除空文件夹。它可以帮助您保持整洁的文件夹结构，特别是在处理大量数据集时。&#xA;3.重命名多个文件# # 用Python脚本重命名目录中的多个文件 import os def rename_files(directory_path, old_name, new_name): for filename in os.</description>
    </item>
    <item>
      <title>1 顺序表</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1-%E9%A1%BA%E5%BA%8F%E8%A1%A8/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1-%E9%A1%BA%E5%BA%8F%E8%A1%A8/</guid>
      <description>突发奇想，想用Python把数据结构的知识再过一遍，所以就开始从顺序表从头来一遍，Python内置了一些功能，感觉只需要定义方法调用就好了，或者不想这么干的话，直接调用内置的方法咯。&#xA;list 是一种元素个数可变的线性表，采用了分离式技术实现的动态顺序表。可以加入和删除元素，并在各种操作中维持已有元素的顺序（即保序）。&#xA;1.1 创建顺序表# # 创建顺序表 def CreateSeqList(self): element = input(&amp;#34;please enter(input #:end):&amp;#34;) while element != &amp;#39;#&amp;#39;: self.seqList.append(int(element)) element = input(&amp;#34;please enter(input #:end):&amp;#34;) 1.2 查找元素# # 查找顺序表中某一个元素 def FindElement(self): key = int(input(&amp;#34;please enter what you want to find:&amp;#34;)) if key in self.seqList: keyPosition = self.seqList.index(key) result = keyPosition else: result = &amp;#34;none&amp;#34; return result 1.3 插入元素# # 在指定位置上插入元素 def InsertElement(self): postion = int(input(&amp;#34;请输入要插入的位置：&amp;#34;)) key = int(input(&amp;#34;请输入要插入的值：&amp;#34;)) print(&amp;#34;插入前顺序：&amp;#34;, self.seqList) self.seqList.insert(postion, key) print(&amp;#34;插入后顺序：&amp;#34;, self.</description>
    </item>
    <item>
      <title>2 单链表</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/2-%E5%8D%95%E9%93%BE%E8%A1%A8/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/2-%E5%8D%95%E9%93%BE%E8%A1%A8/</guid>
      <description>单链表是一种链式的数据结构，链表中的数据用结点表示，保持了数据之间的逻辑关系，但存储空间不一定是按照顺序存储。&#xA;链表的基本元素有：&#xA;节点：包括数据域和指针域，数据域存放数据，指针域存放指向下一个元素的指针 head：头结点 tail：尾结点 None：链表最后一个结点的指针域为None Python中没有显式的指针，但是有引用啊，所以我们可以通过定义节点类和引用来实现链表！&#xA;链表分为单链表和单循环链表，双向链表和双向循环链表，本篇先讲一下单链表：&#xA;2.1 定义节点类# 节点类中包括节点数据和下一个节点地址，即引用&#xA;# 节点类 class Node(object): # 单个节点 初始化 输入一个值data，将值变为一个节点 def __init__(self, data): self.data = data self.next = None # 打印对象中具体的属性值 def __str__(self): # 测试基本功能，输出data return self.data # 输出data print(Node(&amp;#39;data&amp;#39;)) 这里的__str__可以不用写，这里是在进行测试，在后面的具体实现部分可以不用这个，str函数可以方便我们打印对象中具体的属性值，也是很nice了！具体使用如上&#xA;2.2 获取链表的长度# # 获取链表的长度 def length(self): cur = self.head count = 0 while cur is not None: count += 1 cur = cur.next return count 2.3 头插元素# # 头部添加元素 def add_fist(self, data): node = Node(data) node.</description>
    </item>
    <item>
      <title>3 栈</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/3-%E6%A0%88/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/3-%E6%A0%88/</guid>
      <description>栈是一种数据结构，只能从一端插入和删除操作，遵循着先进后出原则存储数据。&#xA;3.1 栈的初始化# def __init__(self): self.stack = [] # 栈列表 self.size = 20 # 栈大小 self.top = -1 # 栈顶位置 3.2 元素进栈# # 元素进栈 def push(self, element): self.stack.append(element) self.top += 1 3.3 元素出栈# # 元素出栈 def pop(self): element = self.stack[-1] self.top -= 1 del self.stack[-1] return element 这里可以直接调用pop函数，使用如下：&#xA;self.stack.pop() # 弹出栈顶元素 3.4 获取栈顶元素# # 获取栈顶位置 def getTop(self): return self.top 这里也可以直接使用列表，使用如下：&#xA;self.stack[-1] 3.5 清空栈# # 清空栈 def empty(self): self.stack = [] self.</description>
    </item>
    <item>
      <title>6 小时 Python 入门</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/6%E5%B0%8F%E6%97%B6python%E5%85%A5%E9%97%A8/6%E5%B0%8F%E6%97%B6python%E5%85%A5%E9%97%A8/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/6%E5%B0%8F%E6%97%B6python%E5%85%A5%E9%97%A8/6%E5%B0%8F%E6%97%B6python%E5%85%A5%E9%97%A8/</guid>
      <description>以下操作均在 Windows 环境下进行操作，先说明一下哈&#xA;一、安装 Python# 1、官网下载 Python&#xA;进入官网（https://www.python.org ），点击 Downloads，选择要下载的版本：&#xA;2、安装 Python&#xA;安装时注意下图勾选部分一定要勾选：&#xA;二、安装代码编辑器 PyCharm# 1、官网下载 PyCharm&#xA;进入官网（https://www.jetbrains.com/pycharm ），点击 Downloads，选择要下载的版本：&#xA;2、安装 PyCharm&#xA;设置安装路径之后，一直点 next 即可。&#xA;3、优化 PyCharm 使用&#xA;三、HelloWorld# 创建第一个项目 HelloWorld &amp;ndash;&amp;gt; 创建文件 app.py &amp;ndash;&amp;gt; 写入代码：&#xA;print(&amp;#34;HelloWorld&amp;#34;) 效果图：&#xA;四、Python 语法# 看语法部分之前，推荐直接看下面入门练习题，潜移默化中对 Python 基本语法会有一定了解之后，再回来看这一部分，会更加熟悉 Python 的使用！&#xA;五、入门练习题# 1.打印 10 个 *# 使用到表达式&#xA;print(&amp;#39;*&amp;#39; * 10) 2.打印价格# 使用到变量&#xA;price = 10 print(price) 3.描述医院病人的信息# #!/usr/bin/env python3 # -*- coding: utf-8 -*- &amp;#34;&amp;#34;&amp;#34; @Time : 2020/5/18 @Author : WuGenQiang @File : hospital @Description : 描述医院病人的信息 &amp;#34;&amp;#34;&amp;#34; full_name = &amp;#39;John Smith&amp;#39; age = 20 is_new = True 4.</description>
    </item>
    <item>
      <title>Anaconda 入门指南</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/anaconda/anaconda%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/anaconda/anaconda%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</guid>
      <description>一、下载安装 Anaconda# 1、下载地址：Anaconda 推荐下载 python3 版本, 毕竟未来 python2 是要停止维护的。&#xA;2、安装 Anaconda&#xA;按照安装程序提示一步步安装就好了, 安装完成之后会多几个应用：&#xA;Anaconda Navigtor ：用于管理工具包和环境的图形用户界面，后续涉及的众多管理命令也可以在 Navigator 中手工实现。 Jupyter notebook ：基于 web 的交互式计算环境，可以编辑易于人们阅读的文档，用于展示数据分析的过程。 qtconsole ：一个可执行 IPython 的仿终端图形界面程序，相比 Python Shell 界面，qtconsole 可以直接显示代码生成的图形，实现多行代码输入执行，以及内置许多有用的功能和函数。 spyder ：一个使用 Python 语言、跨平台的、科学运算集成开发环境。 二、配置环境变量# 如果是 windows 的话需要去 控制面板\系统和安全\系统\高级系统设置\环境变量\用户变量\PATH 中添加 anaconda 的安装目录的 Scripts 文件夹，比如我的路径是D:\developer_tools\python3\Anaconda3\Scripts，看个人安装路径不同需要自己调整。&#xA;之后就可以打开命令行(最好用管理员模式打开) 输入 conda --version&#xA;如果输出conda 4.8.2之类的就说明环境变量设置成功了。&#xA;为了避免可能发生的错误，我们在命令行输入conda upgrade --all 先把所有工具包进行升级。&#xA;三、管理虚拟环境# 接下来我们就可以用 Anaconda 来创建我们一个个独立的 Python 环境了。接下来的例子都是在命令行操作的，请打开你的命令行吧。&#xA;1. activate# activate 能将我们引入 anaconda 设定的虚拟环境中，如果你后面什么参数都不加那么会进入 anaconda 自带的 base 环境。</description>
    </item>
    <item>
      <title>Jupyter notebook 使用指南</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/jupyter-notebook%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/jupyter-notebook%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</guid>
      <description>前言# 在我们的日常学习中，能够编写和运行 Python 文件的程序很多，比如 Python 安装自带的 IDE、程序员喜爱的Pycharm、数据科学全家桶 Anaconda，还有 Spyder、Thonny 等。就我个人使用而言，如果进行大型项目推荐使用 Pycharm，如果进行数据处理和分析，最好选用 Jupyter notebook。可以说，Jupyter notebook 是用Python 进行数据科学、机器学习的必备工具。&#xA;🔊 突出优点：&#xA;学习 Jupyter notebook 非常容易，按照我的教程一步一步做，再自己尝试一下，之后写代码即可健步如飞。&#xA;能够独立运行一个、几个或全部 Python 代码块，更容易看到中间变量的值，从而进行调试&#xA;可以插入 Markdown 说明文字和 Latex 数学公式，让枯燥的代码充满颜值，可读性爆表&#xA;能够调用 Ipython 丰富的“魔法函数”，比如程序计时、重复运行、显示图片等&#xA;写好的代码和文档能够以网页和 ppt 的形式在线分享。在线看 Jupyter notebook 文件 可以在云端远程服务器运行，不需本地安装配置各种环境。体验一下 🔔 文件中包含了 Markdown 说明文档、代码块、代码运行结果、图片嵌入等元素，特别适合 Python 数据科学和机器学习撰写文档。&#xA;🔔 吴恩达的《深度学习》慕课的课后编程作业、大数据竞赛网站 Kaggle 上的代码文档、美国大学的数据科学课程的课后资料及编程作业，都是以 Jupyter notebook 文件的形式给出的，也就是.ipynb文件。&#xA;其实 Jupyter notebook 不止可以运行 Python，还可以运行 Julia、R、Javascript 等语言，这也是jupyter这个名字的由来。Jupyter notebook 支持的编程语言 🔔 Jupyter notebook 集编程和写作于一身，这就叫做“文学编程”。&#xA;安装和运行# 在浏览器网页中运行 Python&#xA;Ipython 内核# Ipython 是更高级的 Python 解释器，而 Jupyter notebook 是基于 Ipython 内核的，在浏览器中以网页形式运行 Python 代码的工具，十分方便。</description>
    </item>
    <item>
      <title>Jupyter添加目录toc</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/anaconda/jupyter%E6%B7%BB%E5%8A%A0toc/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/anaconda/jupyter%E6%B7%BB%E5%8A%A0toc/</guid>
      <description>最近在使用Jupyter notebook的时候感觉到，没有个目录真心难受，当想查找需要的函数的时候，不能很快速的找到，这个时候，要是有个目录就好很多了，很不幸的是，默认Jupyter notebook事没有生成目录这个功能的，但很巧的是，有人已经开发了Jupyter插件，里面包含toc目录功能，开森 🦞&#xA;效果图如下：&#xA;同时toc目录的大小和位置可以随意改变，也支持对每个标题自动编号，默认的就挺好哈哈哈。&#xA;如何安装呢？&#xA;第一步：安装Jupyter notebook&#xA;这个不用说应该都安装了吧，数据分析特别好用的工具，没有之一。&#xA;第二步：安装Jupyter notebook extensions&#xA;conda install -c conda-forge jupyter_contrib_nbextensions 第三步：开启toc插件&#xA;重新运行Jupyter notebook，会发现，多了Nbextensions按钮，点击这个tab，按照下图操作：&#xA;注意：旧版本可能不支持，试试把disable configuration那行前面的✅取消掉再试试，我就是遇到这个问题。&#xA;第四步：生成目录&#xA;创建或者打开一个Jupyter notebook，会发现，多了一个生成目录图标，同时左侧已经支持了目录显示。&#xA;📚 Reference&#xA;[1] https://zhuanlan.zhihu.com/p/24029578/ [2] https://github.com/ipython-contrib/jupyter_contrib_nbextensions [3] https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html </description>
    </item>
    <item>
      <title>Pandas常用操作</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/pandas/pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/pandas/pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</guid>
      <description></description>
    </item>
    <item>
      <title>PyCharm 优化使用</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/pycharm%E4%BC%98%E5%8C%96%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/pycharm%E4%BC%98%E5%8C%96%E4%BD%BF%E7%94%A8/</guid>
      <description>设置 Python 路径（解释器设置）# 1、打开设置对话框&#xA;点击File &amp;ndash;&amp;gt; settings，弹出设置对话框&#xA;2、设置 Python 路径（解释器设置）&#xA;点击 Project &amp;ndash;&amp;gt; Project Interpreter，在右侧 Project Interpreter 下拉，选择 python 路径（若没有，选择 show all），实现 pycharm的 python 路径设置。&#xA;然后如下图操作即可&#xA;设置成功显示下图&#xA;编码设置# Python 的编码问题由来已久，为了避免一步一坑， Pycharm 提供了方便直接的解决方案 在 IDE Encoding、Project Encoding、Property Files 三处都使用 UTF-8 编码，同时在文件头添加&#xA;#-*- coding: utf-8 -* 快捷键风格# 对于常用的快捷键，可以设置为自己熟悉的风格，我选的是 Eclipse。&#xA;File &amp;ndash;&amp;gt; Setting &amp;ndash;&amp;gt; Keymap &amp;ndash;&amp;gt; Keymaps &amp;ndash;&amp;gt; XXX &amp;ndash;&amp;gt; Apply&#xA;改变字体大小# 1、修改代码栏字体&#xA;通过 File &amp;ndash;&amp;gt; Setting &amp;ndash;&amp;gt; Editor &amp;ndash;&amp;gt; Font 调节&#xA;2、修改菜单栏列表框字体</description>
    </item>
    <item>
      <title>第八章 数据规整：聚合、合并和重塑</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch08-%E6%95%B0%E6%8D%AE%E8%A7%84%E6%95%B4%E8%81%9A%E5%90%88%E5%90%88%E5%B9%B6%E5%92%8C%E9%87%8D%E5%A1%91/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch08-%E6%95%B0%E6%8D%AE%E8%A7%84%E6%95%B4%E8%81%9A%E5%90%88%E5%90%88%E5%B9%B6%E5%92%8C%E9%87%8D%E5%A1%91/</guid>
      <description>在许多应用中，数据可能分散在许多文件或数据库中，存储的形式也不利于分析。本章关注可以聚合、合并、重塑数据的方法。&#xA;首先，我会介绍pandas的层次化索引，它广泛用于以上操作。然后，我深入介绍了一些特殊的数据操作。在第14章，你可以看到这些工具的多种应用。&#xA;8.1 层次化索引# 层次化索引（hierarchical indexing）是pandas的一项重要功能，它使你能在一个轴上拥有多个（两个以上）索引级别。抽象点说，它使你能以低维度形式处理高维度数据。我们先来看一个简单的例子：创建一个Series，并用一个由列表或数组组成的列表作为索引：&#xA;In [9]: data = pd.Series(np.random.randn(9), ...: index=[[&amp;#39;a&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;, &amp;#39;d&amp;#39;], ...: [1, 2, 3, 1, 3, 1, 2, 2, 3]]) In [10]: data Out[10]: a 1 -0.204708 2 0.478943 3 -0.519439 b 1 -0.555730 3 1.965781 c 1 1.393406 2 0.092908 d 2 0.281746 3 0.769023 dtype: float64 看到的结果是经过美化的带有MultiIndex索引的Series的格式。索引之间的“间隔”表示“直接使用上面的标签”：&#xA;In [11]: data.index Out[11]: MultiIndex(levels=[[&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;], [1, 2, 3]], labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 2, 0, 1, 1, 2]]) 对于一个层次化索引的对象，可以使用所谓的部分索引，使用它选取数据子集的操作更简单：</description>
    </item>
    <item>
      <title>第二章 Python 语法基础，IPython 和 Jupyter Notebooks</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch02-python%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80%E5%92%8Cipython%E4%BB%A5%E5%8F%8Ajupyternotebooks/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch02-python%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80%E5%92%8Cipython%E4%BB%A5%E5%8F%8Ajupyternotebooks/</guid>
      <description>我们现在使用的库，有 pandas、scikit-learn 和 statsmodels，2017年，数据科学、数据分析和机器学习的资源已经很多，原来通用的科学计算拓展到了计算机科学家、物理学家和其它研究领域的工作人员。学习 Python 和成为软件工程师的优秀书籍也有了。&#xA;因为这本书是专注于 Python 数据处理的，对于一些 Python 的数据结构和库的特性难免不足。因此，本章和第 3 章的内容只够你能学习本书后面的内容。&#xA;在我来看，没有必要为了数据分析而去精通 Python。我鼓励你使用IPython shell和Jupyter试验示例代码，并学习不同类型、函数和方法的文档。虽然我已尽力让本书内容循序渐进，但读者偶尔仍会碰到没有之前介绍过的内容。&#xA;本书大部分内容关注的是基于表格的分析和处理大规模数据集的数据准备工具。为了使用这些工具，必须首先将混乱的数据规整为整洁的表格（或结构化）形式。幸好，Python 是一个理想的语言，可以快速整理数据。Python 使用得越熟练，越容易准备新数据集以进行分析。&#xA;最好在 IPython 和 Jupyter 中亲自尝试本书中使用的工具。当你学会了如何启动 Ipython 和 Jupyter，我建议你跟随示例代码进行练习。与任何键盘驱动的操作环境一样，记住常见的命令也是学习曲线的一部分。&#xA;笔记：本章没有介绍Python的某些概念，如类和面向对象编程，你可能会发现它们在Python数据分析中很有用。 为了加强Python知识，我建议你学习官方Python教程，https://docs.python.org/3/，或是通用的Python教程书籍，比如：&#xA;Python Cookbook，第3版，David Beazley和Brian K. Jones著（O’Reilly） 流畅的Python，Luciano Ramalho著 (O’Reilly) 高效的Python，Brett Slatkin著 (Pearson) 2.1 Python解释器# Python是解释性语言。Python解释器同一时间只能运行一个程序的一条语句。标准的交互Python解释器可以在命令行中通过键入python命令打开：&#xA;wugenqiang@bogon ~ % python Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ] :: Anaconda, Inc. on darwin Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information.</description>
    </item>
    <item>
      <title>第九章 绘图可视化</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch09-%E7%BB%98%E5%9B%BE%E5%92%8C%E5%8F%AF%E8%A7%86%E5%8C%96/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch09-%E7%BB%98%E5%9B%BE%E5%92%8C%E5%8F%AF%E8%A7%86%E5%8C%96/</guid>
      <description>信息可视化（也叫绘图）是数据分析中最重要的工作之一。它可能是探索过程的一部分，例如，帮助我们找出异常值、必要的数据转换、得出有关模型的idea等。另外，做一个可交互的数据可视化也许是工作的最终目标。&#xA;Python有许多库进行静态或动态的数据可视化，但我这里重要关注于matplotlib（http://matplotlib.org/）和基于它的库。&#xA;matplotlib是一个用于创建出版质量图表的桌面绘图包（主要是2D方面）。该项目是由John Hunter于2002年启动的，其目的是为Python构建一个MATLAB式的绘图接口。matplotlib和IPython社区进行合作，简化了从IPython shell（包括现在的Jupyter notebook）进行交互式绘图。matplotlib支持各种操作系统上许多不同的GUI后端，而且还能将图片导出为各种常见的矢量（vector）和光栅（raster）图：PDF、SVG、JPG、PNG、BMP、GIF等。除了几张，本书中的大部分图都是用它生成的。&#xA;随着时间的发展，matplotlib衍生出了多个数据可视化的工具集，它们使用matplotlib作为底层。其中之一是seaborn（http://seaborn.pydata.org/），本章后面会学习它。&#xA;学习本章代码案例的最简单方法是在Jupyter notebook进行交互式绘图。在Jupyter notebook中执行下面的语句：&#xA;%matplotlib notebook 9.1 matplotlib API入门# matplotlib的通常引入约定是：&#xA;In [11]: import matplotlib.pyplot as plt 在Jupyter中运行%matplotlib notebook（或在IPython中运行%matplotlib），就可以创建一个简单的图形。如果一切设置正确，会看到图9-1：&#xA;In [12]: import numpy as np In [13]: data = np.arange(10) In [14]: data Out[14]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) In [15]: plt.plot(data) 虽然seaborn这样的库和pandas的内置绘图函数能够处理许多普通的绘图任务，但如果需要自定义一些高级功能的话就必须学习matplotlib API。&#xA;笔记：虽然本书没有详细地讨论matplotlib的各种功能，但足以将你引入门。matplotlib的示例库和文档是学习高级特性的最好资源。&#xA;9.1.1 Figure和Subplot# matplotlib的图像都位于Figure对象中。你可以用plt.figure创建一个新的Figure：&#xA;In [16]: fig = plt.figure() 如果用的是IPython，这时会弹出一个空窗口，但在Jupyter中，必须再输入更多命令才能看到。plt.figure有一些选项，特别是figsize，它用于确保当图片保存到磁盘时具有一定的大小和纵横比。&#xA;不能通过空Figure绘图。必须用add_subplot创建一个或多个subplot才行：&#xA;In [17]: ax1 = fig.add_subplot(2, 2, 1) 这条代码的意思是：图像应该是2×2的（即最多4张图），且当前选中的是4个subplot中的第一个（编号从1开始）。如果再把后面两个subplot也创建出来，最终得到的图像如图9-2所示：</description>
    </item>
    <item>
      <title>第六章 数据加载、存储与文件格式</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch06-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%AD%98%E5%82%A8%E4%B8%8E%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch06-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%AD%98%E5%82%A8%E4%B8%8E%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/</guid>
      <description>访问数据是使用本书所介绍的这些工具的第一步。我会着重介绍pandas的数据输入与输出，虽然别的库中也有不少以此为目的的工具。&#xA;输入输出通常可以划分为几个大类：读取文本文件和其他更高效的磁盘存储格式，加载数据库中的数据，利用Web API操作网络资源。&#xA;6.1 读写文本格式的数据# pandas提供了一些用于将表格型数据读取为DataFrame对象的函数。表6-1对它们进行了总结，其中read_csv和read_table可能会是你今后用得最多的。&#xA;我将大致介绍一下这些函数在将文本数据转换为DataFrame时所用到的一些技术。这些函数的选项可以划分为以下几个大类：&#xA;索引：将一个或多个列当做返回的DataFrame处理，以及是否从文件、用户获取列名。 类型推断和数据转换：包括用户定义值的转换、和自定义的缺失值标记列表等。 日期解析：包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列。 迭代：支持对大文件进行逐块迭代。 不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西（比如由成千上万个逗号隔开的数值数据）。 因为工作中实际碰到的数据可能十分混乱，一些数据加载函数（尤其是read_csv）的选项逐渐变得复杂起来。面对不同的参数，感到头痛很正常（read_csv有超过50个参数）。pandas文档有这些参数的例子，如果你感到阅读某个文件很难，可以通过相似的足够多的例子找到正确的参数。&#xA;其中一些函数，比如pandas.read_csv，有类型推断功能，因为列数据的类型不属于数据类型。也就是说，你不需要指定列的类型到底是数值、整数、布尔值，还是字符串。其它的数据格式，如HDF5、Feather和msgpack，会在格式中存储数据类型。&#xA;日期和其他自定义类型的处理需要多花点工夫才行。首先我们来看一个以逗号分隔的（CSV）文本文件：&#xA;In [8]: !cat examples/ex1.csv a,b,c,d,message 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo 笔记：这里，我用的是Unix的cat shell命令将文件的原始内容打印到屏幕上。如果你用的是Windows，你可以使用type达到同样的效果。&#xA;由于该文件以逗号分隔，所以我们可以使用read_csv将其读入一个DataFrame：&#xA;In [9]: df = pd.read_csv(&amp;#39;examples/ex1.csv&amp;#39;) In [10]: df Out[10]: a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 我们还可以使用read_table，并指定分隔符：&#xA;In [11]: pd.read_table(&amp;#39;examples/ex1.csv&amp;#39;, sep=&amp;#39;,&amp;#39;) Out[11]: a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 并不是所有文件都有标题行。看看下面这个文件：</description>
    </item>
    <item>
      <title>第七章 数据清洗和准备</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch07-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E5%92%8C%E5%87%86%E5%A4%87/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch07-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E5%92%8C%E5%87%86%E5%A4%87/</guid>
      <description>在数据分析和建模的过程中，相当多的时间要用在数据准备上：加载、清理、转换以及重塑。这些工作会占到分析师时间的80%或更多。有时，存储在文件和数据库中的数据的格式不适合某个特定的任务。许多研究者都选择使用通用编程语言（如Python、Perl、R或Java）或UNIX文本处理工具（如sed或awk）对数据格式进行专门处理。幸运的是，pandas和内置的Python标准库提供了一组高级的、灵活的、快速的工具，可以让你轻松地将数据规整为想要的格式。&#xA;实际上，pandas的许多设计和实现都是由真实应用的需求所驱动的。&#xA;在本章中，我会讨论处理缺失数据、重复数据、字符串操作和其它分析数据转换的工具。下一章，我会关注于用多种方法合并、重塑数据集。&#xA;7.1 处理缺失数据# 在许多数据分析工作中，缺失数据是经常发生的。pandas的目标之一就是尽量轻松地处理缺失数据。例如，pandas对象的所有描述性统计默认都不包括缺失数据。&#xA;缺失数据在pandas中呈现的方式有些不完美，但对于大多数用户可以保证功能正常。对于数值数据，pandas使用浮点值NaN（Not a Number）表示缺失数据。我们称其为哨兵值，可以方便的检测出来：&#xA;In [10]: string_data = pd.Series([&amp;#39;aardvark&amp;#39;, &amp;#39;artichoke&amp;#39;, np.nan, &amp;#39;avocado&amp;#39;]) In [11]: string_data Out[11]: 0 aardvark 1 artichoke 2 NaN 3 avocado dtype: object In [12]: string_data.isnull() Out[12]: 0 False 1 False 2 True 3 False dtype: bool 在pandas中，我们采用了R语言中的惯用法，即将缺失值表示为NA，它表示不可用not available。在统计应用中，NA数据可能是不存在的数据或者虽然存在，但是没有观察到（例如，数据采集中发生了问题）。当进行数据清洗以进行分析时，最好直接对缺失数据进行分析，以判断数据采集的问题或缺失数据可能导致的偏差。&#xA;Python内置的None值在对象数组中也可以作为NA：&#xA;In [13]: string_data[0] = None In [14]: string_data.isnull() Out[14]: 0 True 1 False 2 True 3 False dtype: bool pandas项目中还在不断优化内部细节以更好处理缺失数据，像用户API功能，例如pandas.isnull，去除了许多恼人的细节。表7-1列出了一些关于缺失数据处理的函数。&#xA;7.1.1 滤除缺失数据# 过滤掉缺失数据的办法有很多种。你可以通过pandas.</description>
    </item>
    <item>
      <title>第三章 Python 的数据结构、函数和文件</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch03-python%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%87%BD%E6%95%B0%E5%92%8C%E6%96%87%E4%BB%B6/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch03-python%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%87%BD%E6%95%B0%E5%92%8C%E6%96%87%E4%BB%B6/</guid>
      <description>🐹 本章讨论Python的内置功能，这些功能本书会用到很多。虽然扩展库，比如pandas和Numpy，使处理大数据集很方便，但它们是和Python的内置数据处理工具一同使用的。&#xA;我们会从Python最基础的数据结构开始：元组、列表、字典和集合。然后会讨论创建你自己的、可重复使用的Python函数。最后，会学习Python的文件对象，以及如何与本地硬盘交互。&#xA;3.1 数据结构和序列# Python的数据结构简单而强大。通晓它们才能成为熟练的Python程序员。&#xA;3.1.1 元组# 元组是一个固定长度，不可改变的Python序列对象。创建元组的最简单方式，是用逗号分隔一列值：&#xA;In [1]: tup = 4, 5, 6 In [2]: tup Out[2]: (4, 5, 6) 当用复杂的表达式定义元组，最好将值放到圆括号内，如下所示：&#xA;In [3]: nested_tup = (4, 5, 6), (7, 8) In [4]: nested_tup Out[4]: ((4, 5, 6), (7, 8)) 用tuple可以将任意序列或迭代器转换成元组：&#xA;In [5]: tuple([4, 0, 2]) Out[5]: (4, 0, 2) In [6]: tup = tuple(&amp;#39;string&amp;#39;) In [7]: tup Out[7]: (&amp;#39;s&amp;#39;, &amp;#39;t&amp;#39;, &amp;#39;r&amp;#39;, &amp;#39;i&amp;#39;, &amp;#39;n&amp;#39;, &amp;#39;g&amp;#39;) 可以用方括号访问元组中的元素。和C、C++、JAVA等语言一样，序列是从0开始的：&#xA;In [8]: tup[0] Out[8]: &amp;#39;s&amp;#39; 元组中存储的对象可能是可变对象。一旦创建了元组，元组中的对象就不能修改了：</description>
    </item>
    <item>
      <title>第十二章 Pandas 高级应用</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch12-pandas%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch12-pandas%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</guid>
      <description>前面的章节关注于不同类型的数据规整流程和NumPy、pandas与其它库的特点。随着时间的发展，pandas发展出了更多适合高级用户的功能。本章就要深入学习pandas的高级功能。&#xA;12.1 分类数据# 这一节介绍的是pandas的分类类型。我会向你展示通过使用它，提高性能和内存的使用率。我还会介绍一些在统计和机器学习中使用分类数据的工具。&#xA;12.1.1 背景和目的# 表中的一列通常会有重复的包含不同值的小集合的情况。我们已经学过了unique和value_counts，它们可以从数组提取出不同的值，并分别计算频率：&#xA;In [10]: import numpy as np; import pandas as pd In [11]: values = pd.Series([&amp;#39;apple&amp;#39;, &amp;#39;orange&amp;#39;, &amp;#39;apple&amp;#39;, ....: &amp;#39;apple&amp;#39;] * 2) In [12]: values Out[12]: 0 apple 1 orange 2 apple 3 apple 4 apple 5 orange 6 apple 7 apple dtype: object In [13]: pd.unique(values) Out[13]: array([&amp;#39;apple&amp;#39;, &amp;#39;orange&amp;#39;], dtype=object) In [14]: pd.value_counts(values) Out[14]: apple 6 orange 2 dtype: int64 许多数据系统（数据仓库、统计计算或其它应用）都发展出了特定的表征重复值的方法，以进行高效的存储和计算。在数据仓库中，最好的方法是使用所谓的包含不同值的维表(Dimension Table)，将主要的参数存储为引用维表整数键：&#xA;In [15]: values = pd.</description>
    </item>
    <item>
      <title>第十三章 Python 建模库介绍</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch13-python%E5%BB%BA%E6%A8%A1%E5%BA%93%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch13-python%E5%BB%BA%E6%A8%A1%E5%BA%93%E4%BB%8B%E7%BB%8D/</guid>
      <description>本书中，我已经介绍了Python数据分析的编程基础。因为数据分析师和科学家总是在数据规整和准备上花费大量时间，这本书的重点在于掌握这些功能。&#xA;开发模型选用什么库取决于应用本身。许多统计问题可以用简单方法解决，比如普通的最小二乘回归，其它问题可能需要复杂的机器学习方法。幸运的是，Python已经成为了运用这些分析方法的语言之一，因此读完此书，你可以探索许多工具。&#xA;本章中，我会回顾一些pandas的特点，在你胶着于pandas数据规整和模型拟合和评分时，它们可能派上用场。然后我会简短介绍两个流行的建模工具，statsmodels和scikit-learn。这二者每个都值得再写一本书，我就不做全面的介绍，而是建议你学习两个项目的线上文档和其它基于Python的数据科学、统计和机器学习的书籍。&#xA;13.1 pandas与模型代码的接口# 模型开发的通常工作流是使用pandas进行数据加载和清洗，然后切换到建模库进行建模。**开发模型的重要一环是机器学习中的“特征工程”。**它可以描述从原始数据集中提取信息的任何数据转换或分析，这些数据集可能在建模中有用。本书中学习的数据聚合和GroupBy工具常用于特征工程中。&#xA;优秀的特征工程超出了本书的范围，我会尽量直白地介绍一些用于数据操作和建模切换的方法。&#xA;pandas与其它分析库通常是靠NumPy的数组联系起来的。将DataFrame转换为NumPy数组，可以使用.values属性：&#xA;In [10]: import pandas as pd In [11]: import numpy as np In [12]: data = pd.DataFrame({ ....: &amp;#39;x0&amp;#39;: [1, 2, 3, 4, 5], ....: &amp;#39;x1&amp;#39;: [0.01, -0.01, 0.25, -4.1, 0.], ....: &amp;#39;y&amp;#39;: [-1.5, 0., 3.6, 1.3, -2.]}) In [13]: data Out[13]: x0 x1 y 0 1 0.01 -1.5 1 2 -0.01 0.0 2 3 0.25 3.6 3 4 -4.10 1.3 4 5 0.</description>
    </item>
    <item>
      <title>第十四章 数据分析案例</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch14-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch14-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/</guid>
      <description>本书正文的最后一章，我们来看一些真实世界的数据集。对于每个数据集，我们会用之前介绍的方法，从原始数据中提取有意义的内容。展示的方法适用于其它数据集，也包括你的。本章包含了一些各种各样的案例数据集，可以用来练习。&#xA;案例数据集可以在Github仓库找到，见第一章。&#xA;14.1 来自Bitly的USA.gov数据# 2011年，URL缩短服务Bitly跟美国政府网站USA.gov合作，提供了一份从生成.gov或.mil短链接的用户那里收集来的匿名数据。在2011年，除实时数据之外，还可以下载文本文件形式的每小时快照。写作此书时（2017年），这项服务已经关闭，但我们保存一份数据用于本书的案例。&#xA;以每小时快照为例，文件中各行的格式为JSON（即JavaScript Object Notation，这是一种常用的Web数据格式）。例如，如果我们只读取某个文件中的第一行，那么所看到的结果应该是下面这样：&#xA;In [5]: path = &amp;#39;datasets/bitly_usagov/example.txt&amp;#39; In [6]: open(path).readline() Out[6]: &amp;#39;{ &amp;#34;a&amp;#34;: &amp;#34;Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11 (KHTML, like Gecko) Chrome\\/17.0.963.78 Safari\\/535.11&amp;#34;, &amp;#34;c&amp;#34;: &amp;#34;US&amp;#34;, &amp;#34;nk&amp;#34;: 1, &amp;#34;tz&amp;#34;: &amp;#34;America\\/New_York&amp;#34;, &amp;#34;gr&amp;#34;: &amp;#34;MA&amp;#34;, &amp;#34;g&amp;#34;: &amp;#34;A6qOVH&amp;#34;, &amp;#34;h&amp;#34;: &amp;#34;wfLQtf&amp;#34;, &amp;#34;l&amp;#34;: &amp;#34;orofrog&amp;#34;, &amp;#34;al&amp;#34;: &amp;#34;en-US,en;q=0.8&amp;#34;, &amp;#34;hh&amp;#34;: &amp;#34;1.usa.gov&amp;#34;, &amp;#34;r&amp;#34;: &amp;#34;http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf&amp;#34;, &amp;#34;u&amp;#34;: &amp;#34;http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991&amp;#34;, &amp;#34;t&amp;#34;: 1331923247, &amp;#34;hc&amp;#34;: 1331822918, &amp;#34;cy&amp;#34;: &amp;#34;Danvers&amp;#34;, &amp;#34;ll&amp;#34;: [ 42.576698, -70.954903 ] }\n&amp;#39; Python有内置或第三方模块可以将JSON字符串转换成Python字典对象。这里，我将使用json模块及其loads函数逐行加载已经下载好的数据文件：&#xA;import json path = &amp;#39;datasets/bitly_usagov/example.txt&amp;#39; records = [json.</description>
    </item>
    <item>
      <title>第十一章 时间序列</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch11-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch11-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/</guid>
      <description>时间序列（time series）数据是一种重要的结构化数据形式，应用于多个领域，包括金融学、经济学、生态学、神经科学、物理学等。在多个时间点观察或测量到的任何事物都可以形成一段时间序列。很多时间序列是固定频率的，也就是说，数据点是根据某种规律定期出现的（比如每15秒、每5分钟、每月出现一次）。时间序列也可以是不定期的，没有固定的时间单位或单位之间的偏移量。时间序列数据的意义取决于具体的应用场景，主要有以下几种：&#xA;时间戳（timestamp），特定的时刻。 固定时期（period），如2007年1月或2010年全年。 时间间隔（interval），由起始和结束时间戳表示。时期（period）可以被看做间隔（interval）的特例。 实验或过程时间，每个时间点都是相对于特定起始时间的一个度量。例如，从放入烤箱时起，每秒钟饼干的直径。 本章主要讲解前3种时间序列。许多技术都可用于处理实验型时间序列，其索引可能是一个整数或浮点数（表示从实验开始算起已经过去的时间）。最简单也最常见的时间序列都是用时间戳进行索引的。&#xA;提示：pandas也支持基于timedeltas的指数，它可以有效代表实验或经过的时间。这本书不涉及timedelta指数，但你可以学习pandas的文档（http://pandas.pydata.org/）。&#xA;pandas提供了许多内置的时间序列处理工具和数据算法。因此，你可以高效处理非常大的时间序列，轻松地进行切片/切块、聚合、对定期/不定期的时间序列进行重采样等。有些工具特别适合金融和经济应用，你当然也可以用它们来分析服务器日志数据。&#xA;11.1 日期和时间数据类型及工具# Python标准库包含用于日期（date）和时间（time）数据的数据类型，而且还有日历方面的功能。我们主要会用到datetime、time以及calendar模块。datetime.datetime（也可以简写为datetime）是用得最多的数据类型：&#xA;In [10]: from datetime import datetime In [11]: now = datetime.now() In [12]: now Out[12]: datetime.datetime(2017, 9, 25, 14, 5, 52, 72973) In [13]: now.year, now.month, now.day Out[13]: (2017, 9, 25) datetime以毫秒形式存储日期和时间。timedelta表示两个datetime对象之间的时间差：&#xA;In [14]: delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15) In [15]: delta Out[15]: datetime.timedelta(926, 56700) In [16]: delta.days Out[16]: 926 In [17]: delta.</description>
    </item>
    <item>
      <title>第十章 数据聚合与分组运算</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch10-%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88%E4%B8%8E%E5%88%86%E7%BB%84%E8%BF%90%E7%AE%97/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch10-%E6%95%B0%E6%8D%AE%E8%81%9A%E5%90%88%E4%B8%8E%E5%88%86%E7%BB%84%E8%BF%90%E7%AE%97/</guid>
      <description>对数据集进行分组并对各组应用一个函数（无论是聚合还是转换），通常是数据分析工作中的重要环节。在将数据集加载、融合、准备好之后，通常就是计算分组统计或生成透视表。pandas提供了一个灵活高效的groupby功能，它使你能以一种自然的方式对数据集进行切片、切块、摘要等操作。&#xA;关系型数据库和SQL（Structured Query Language，结构化查询语言）能够如此流行的原因之一就是其能够方便地对数据进行连接、过滤、转换和聚合。但是，像SQL这样的查询语言所能执行的分组运算的种类很有限。在本章中你将会看到，由于Python和pandas强大的表达能力，我们可以执行复杂得多的分组运算（利用任何可以接受pandas对象或NumPy数组的函数）。在本章中，你将会学到：&#xA;使用一个或多个键（形式可以是函数、数组或DataFrame列名）分割pandas对象。 计算分组的概述统计，比如数量、平均值或标准差，或是用户定义的函数。 应用组内转换或其他运算，如规格化、线性回归、排名或选取子集等。 计算透视表或交叉表。 执行分位数分析以及其它统计分组分析。 笔记：对时间序列数据的聚合（groupby的特殊用法之一）也称作重采样（resampling），将在第11章中单独对其进行讲解。&#xA;10.1 GroupBy机制# Hadley Wickham（许多热门R语言包的作者）创造了一个用于表示分组运算的术语&amp;quot;split-apply-combine&amp;quot;（拆分－应用－合并）。第一个阶段，pandas对象（无论是Series、DataFrame还是其他的）中的数据会根据你所提供的一个或多个键被拆分（split）为多组。拆分操作是在对象的特定轴上执行的。例如，DataFrame可以在其行（axis=0）或列（axis=1）上进行分组。然后，将一个函数应用（apply）到各个分组并产生一个新值。最后，所有这些函数的执行结果会被合并（combine）到最终的结果对象中。结果对象的形式一般取决于数据上所执行的操作。图10-1大致说明了一个简单的分组聚合过程。&#xA;分组键可以有多种形式，且类型不必相同：&#xA;列表或数组，其长度与待分组的轴一样。 表示DataFrame某个列名的值。 字典或Series，给出待分组轴上的值与分组名之间的对应关系。 函数，用于处理轴索引或索引中的各个标签。 注意，后三种都只是快捷方式而已，其最终目的仍然是产生一组用于拆分对象的值。如果觉得这些东西看起来很抽象，不用担心，我将在本章中给出大量有关于此的示例。首先来看看下面这个非常简单的表格型数据集（以DataFrame的形式）：&#xA;In [10]: df = pd.DataFrame({&amp;#39;key1&amp;#39; : [&amp;#39;a&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;a&amp;#39;], ....: &amp;#39;key2&amp;#39; : [&amp;#39;one&amp;#39;, &amp;#39;two&amp;#39;, &amp;#39;one&amp;#39;, &amp;#39;two&amp;#39;, &amp;#39;one&amp;#39;], ....: &amp;#39;data1&amp;#39; : np.random.randn(5), ....: &amp;#39;data2&amp;#39; : np.random.randn(5)}) In [11]: df Out[11]: data1 data2 key1 key2 0 -0.204708 1.393406 a one 1 0.478943 0.092908 a two 2 -0.519439 0.281746 b one 3 -0.</description>
    </item>
    <item>
      <title>第四章 Numpy 基础</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch04-numpy%E5%9F%BA%E7%A1%80%E6%95%B0%E7%BB%84%E5%92%8C%E7%9F%A2%E9%87%8F%E8%AE%A1%E7%AE%97/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch04-numpy%E5%9F%BA%E7%A1%80%E6%95%B0%E7%BB%84%E5%92%8C%E7%9F%A2%E9%87%8F%E8%AE%A1%E7%AE%97/</guid>
      <description>NumPy（Numerical Python的简称）是Python数值计算最重要的基础包。大多数提供科学计算的包都是用NumPy的数组作为构建基础。&#xA;NumPy的部分功能如下：&#xA;ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。 用于对整组数据进行快速运算的标准数学函数（无需编写循环）。 用于读写磁盘数据的工具以及用于操作内存映射文件的工具。 线性代数、随机数生成以及傅里叶变换功能。 用于集成由C、C++、Fortran等语言编写的代码的A C API。 由于NumPy提供了一个简单易用的C API，因此很容易将数据传递给由低级语言编写的外部库，外部库也能以NumPy数组的形式将数据返回给Python。这个功能使Python成为一种包装C/C++/Fortran历史代码库的选择，并使被包装库拥有一个动态的、易用的接口。&#xA;NumPy本身并没有提供多么高级的数据分析功能，理解NumPy数组以及面向数组的计算将有助于你更加高效地使用诸如pandas之类的工具。因为NumPy是一个很大的题目，我会在附录A中介绍更多NumPy高级功能，比如广播。&#xA;对于大部分数据分析应用而言，我最关注的功能主要集中在：&#xA;用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。 常用的数组算法，如排序、唯一化、集合运算等。 高效的描述统计和数据聚合/摘要运算。 用于异构数据集的合并/连接运算的数据对齐和关系型数据运算。 将条件逻辑表述为数组表达式（而不是带有if-elif-else分支的循环）。 数据的分组运算（聚合、转换、函数应用等）。。 虽然NumPy提供了通用的数值数据处理的计算基础，但大多数读者可能还是想将pandas作为统计和分析工作的基础，尤其是处理表格数据时。pandas还提供了一些NumPy所没有的领域特定的功能，如时间序列处理等。&#xA;🐰 笔记：Python的面向数组计算可以追溯到1995年，Jim Hugunin创建了Numeric库。接下来的10年，许多科学编程社区纷纷开始使用Python的数组编程，但是进入21世纪，库的生态系统变得碎片化了。2005年，Travis Oliphant从Numeric和Numarray项目整合出了NumPy项目，进而所有社区都集合到了这个框架下。&#xA;NumPy对于数值计算特别重要的原因之一，是**因为它可以高效处理大数组的数据。**这是因为：&#xA;NumPy是在一个连续的内存块中存储数据，独立于其他Python内置对象。NumPy的C语言编写的算法库可以操作内存，而不必进行类型检查或其它前期工作。比起Python的内置序列，NumPy数组使用的内存更少。 NumPy可以在整个数组上执行复杂的计算，而不需要Python的for循环。 要搞明白具体的性能差距，考察一个包含一百万整数的数组，和一个等价的Python列表：&#xA;In [7]: import numpy as np In [8]: my_arr = np.arange(1000000) In [9]: my_list = list(range(1000000)) 各个序列分别乘以2：&#xA;In [10]: %time for _ in range(10): my_arr2 = my_arr * 2 CPU times: user 20 ms, sys: 50 ms, total: 70 ms Wall time: 72.</description>
    </item>
    <item>
      <title>第五章 Pandas 入门</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch05-pandas%E5%85%A5%E9%97%A8/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch05-pandas%E5%85%A5%E9%97%A8/</guid>
      <description>pandas是本书后续内容的首选库。它含有使数据清洗和分析工作变得更快更简单的数据结构和操作工具。pandas经常和其它工具一同使用，如数值计算工具NumPy和SciPy，分析库statsmodels和scikit-learn，和数据可视化库matplotlib。pandas是基于NumPy数组构建的，特别是基于数组的函数和不使用for循环的数据处理。&#xA;虽然pandas采用了大量的NumPy编码风格，但二者最大的不同是pandas是专门为处理表格和混杂数据设计的。而NumPy更适合处理统一的数值数组数据。&#xA;自从2010年pandas开源以来，pandas逐渐成长为一个非常大的库，应用于许多真实案例。开发者社区已经有了800个独立的贡献者，他们在解决日常数据问题的同时为这个项目提供贡献。&#xA;在本书后续部分中，我将使用下面这样的pandas引入约定：&#xA;In [1]: import pandas as pd 因此，只要你在代码中看到pd.，就得想到这是pandas。因为Series和DataFrame用的次数非常多，所以将其引入本地命名空间中会更方便：&#xA;In [2]: from pandas import Series, DataFrame 5.1 pandas的数据结构介绍# 要使用pandas，你首先就得熟悉它的两个主要数据结构：Series和DataFrame。虽然它们并不能解决所有问题，但它们为大多数应用提供了一种可靠的、易于使用的基础。&#xA;5.1.1 Series# Series是一种类似于一维数组的对象，它由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。仅由一组数据即可产生最简单的Series：&#xA;In [11]: obj = pd.Series([4, 7, -5, 3]) In [12]: obj Out[12]: 0 4 1 7 2 -5 3 3 dtype: int64 Series的字符串表现形式为：索引在左边，值在右边。由于我们没有为数据指定索引，于是会自动创建一个0到N-1（N为数据的长度）的整数型索引。你可以通过Series 的values和index属性获取其数组表示形式和索引对象：&#xA;In [13]: obj.values Out[13]: array([ 4, 7, -5, 3]) In [14]: obj.index # like range(4) Out[14]: RangeIndex(start=0, stop=4, step=1) 通常，我们希望所创建的Series带有一个可以对各个数据点进行标记的索引：&#xA;In [15]: obj2 = pd.</description>
    </item>
    <item>
      <title>第一章 准备工作</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch01-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/ch01-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C/</guid>
      <description>1.1 本书的内容# Python 数据分析这本书讲的是利用 Python 进行数据控制、处理、整理、分析等方面的具体细节和基本要点。作者介绍 Python 编程和用于数据处理的库和工具环境，掌握这些，可以让你成为一个数据分析专家。虽然本书的标题是“数据分析”，重点却是 Python 编程、库，以及用于数据分析的工具。这就是数据分析要用到的 Python 编程。&#xA;1.1.1 什么样的数据？# 🔰 当书中出现“数据”时，究竟指的是什么呢？&#xA;主要指的是结构化数据（structured data），这个故意含糊其辞的术语代指了所有通用格式的数据，例如：&#xA;表格型数据，其中各列可能是不同的类型（字符串、数值、日期等）。比如保存在关系型数据库中或以制表符/逗号为分隔符的文本文件中的那些数据。 多维数组（矩阵）。 通过关键列（对于 SQL 用户而言，就是主键和外键）相互联系的多个表。 间隔平均或不平均的时间序列。 这绝不是一个完整的列表。大部分数据集都能被转化为更加适合分析和建模的结构化形式，虽然有时这并不是很明显。如果不行的话，也可以将数据集的特征提取为某种结构化形式。例如，一组新闻文章可以被处理为一张词频表，而这张词频表就可以用于情感分析。&#xA;大部分电子表格软件（比如 Microsoft Excel，它可能是世界上使用最广泛的数据分析工具了）的用户不会对此类数据感到陌生。&#xA;1.2 为什么要使用 Python 进行数据分析# 许许多多的人（包括我自己）都很容易爱上 Python 这门语言。自从1991年诞生以来，Python 现在已经成为最受欢迎的动态编程语言之一，其他还有Perl、Ruby等。由于拥有大量的Web框架（比如Rails（Ruby）和Django（Python）），自从2005年，使用Python和Ruby进行网站建设工作非常流行。这些语言常被称作脚本（scripting）语言，因为它们可以用于编写简短而粗糙的小程序（也就是脚本）。我个人并不喜欢“脚本语言”这个术语，因为它好像在说这些语言无法用于构建严谨的软件。在众多解释型语言中，由于各种历史和文化的原因，Python发展出了一个巨大而活跃的科学计算（scientific computing）社区。在过去的10年，Python从一个边缘或“自担风险”的科学计算语言，成为了数据科学、机器学习、学界和工业界软件开发最重要的语言之一。&#xA;在数据分析、交互式计算以及数据可视化方面，Python将不可避免地与其他开源和商业的领域特定编程语言/工具进行对比，如R、MATLAB、SAS、Stata等。近年来，由于Python的库（例如pandas和scikit-learn）不断改良，使其成为数据分析任务的一个优选方案。结合其在通用编程方面的强大实力，我们完全可以只使用Python这一种语言构建以数据为中心的应用。&#xA;1.2.1 Python作为胶水语言# Python成为成功的科学计算工具的部分原因是，它能够轻松地集成C、C++以及Fortran代码。大部分现代计算环境都利用了一些Fortran和C库来实现线性代数、优选、积分、快速傅里叶变换以及其他诸如此类的算法。许多企业和国家实验室也利用Python来“粘合”那些已经用了多年的遗留软件系统。&#xA;大多数软件都是由两部分代码组成的：少量需要占用大部分执行时间的代码，以及大量不经常执行的“胶水代码”。大部分情况下，胶水代码的执行时间是微不足道的。开发人员的精力几乎都是花在优化计算瓶颈上面，有时更是直接转用更低级的语言（比如C）。&#xA;1.2.2 解决“两种语言”问题# 很多组织通常都会用一种类似于领域特定的计算语言（如SAS和R）对新想法做研究、原型构建和测试，然后再将这些想法移植到某个更大的生产系统中去（可能是用Java、C#或C++编写的）。人们逐渐意识到，Python不仅适用于研究和原型构建，同时也适用于构建生产系统。为什么一种语言就够了，却要使用两个语言的开发环境呢？我相信越来越多的企业也会这样看，因为研究人员和工程技术人员使用同一种编程工具将会给企业带来非常显著的组织效益。&#xA;1.2.3 为什么不选Python# 虽然Python非常适合构建分析应用以及通用系统，但它对不少应用场景适用性较差。&#xA;由于Python是一种解释型编程语言，因此大部分Python代码都要比用编译型语言（比如Java和C++）编写的代码运行慢得多。由于程序员的时间通常都比CPU时间值钱，因此许多人也愿意对此做一些取舍。但是，在那些延迟要求非常小或高资源利用率的应用中（例如高频交易系统），耗费时间使用诸如C++这样更低级、更低生产率的语言进行编程也是值得的。&#xA;对于高并发、多线程的应用程序而言（尤其是拥有许多计算密集型线程的应用程序），Python并不是一种理想的编程语言。这是因为Python有一个叫做全局解释器锁（Global Interpreter Lock，GIL）的组件，这是一种防止解释器同时执行多条Python字节码指令的机制。有关“为什么会存在GIL”的技术性原因超出了本书的范围。虽然很多大数据处理应用程序为了能在较短的时间内完成数据集的处理工作都需要运行在计算机集群上，但是仍然有一些情况需要用单进程多线程系统来解决。&#xA;这并不是说Python不能执行真正的多线程并行代码。例如，Python的C插件使用原生的C或C++的多线程，可以并行运行而不被GIL影响，只要它们不频繁地与Python对象交互。&#xA;1.3 重要的Python库# 考虑到那些还不太了解Python科学计算生态系统和库的读者，下面我先对各个库做一个简单的介绍。&#xA;1.3.1 NumPy# NumPy（Numerical Python的简称）是Python科学计算的基础包。本书大部分内容都基于NumPy以及构建于其上的库。它提供了以下功能（不限于此）：&#xA;快速高效的多维数组对象ndarray。&#xA;用于对数组执行元素级计算以及直接对数组执行数学运算的函数。&#xA;用于读写硬盘上基于数组的数据集的工具。&#xA;线性代数运算、傅里叶变换，以及随机数生成。&#xA;-成熟的C API， 用于Python插件和原生C、C++、Fortran代码访问NumPy的数据结构和计算工具。&#xA;除了为Python提供快速的数组处理能力，NumPy在数据分析方面还有另外一个主要作用，即作为在算法和库之间传递数据的容器。对于数值型数据，NumPy数组在存储和处理数据时要比内置的Python数据结构高效得多。此外，由低级语言（比如C和Fortran）编写的库可以直接操作NumPy数组中的数据，无需进行任何数据复制工作。因此，许多Python的数值计算工具要么使用NumPy数组作为主要的数据结构，要么可以与NumPy进行无缝交互操作。&#xA;1.3.2 pandas# pandas提供了快速便捷处理结构化数据的大量数据结构和函数。自从2010年出现以来，它助使Python成为强大而高效的数据分析环境。本书用得最多的pandas对象是DataFrame，它是一个面向列（column-oriented）的二维表结构，另一个是Series，一个一维的标签化数组对象。</description>
    </item>
    <item>
      <title>附录A-NumPy高级应用</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E9%99%84%E5%BD%95a-numpy%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E9%99%84%E5%BD%95a-numpy%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8/</guid>
      <description>在这篇附录中，我会深入NumPy库的数组计算。这会包括ndarray更内部的细节，和更高级的数组操作和算法。&#xA;本章包括了一些杂乱的章节，不需要仔细研究。&#xA;A.1 ndarray对象的内部机理# NumPy的ndarray提供了一种将同质数据块（可以是连续或跨越）解释为多维数组对象的方式。正如你之前所看到的那样，数据类型（dtype）决定了数据的解释方式，比如浮点数、整数、布尔值等。&#xA;ndarray如此强大的部分原因是所有数组对象都是数据块的一个跨度视图（strided view）。你可能想知道数组视图arr[::2,::-1]不复制任何数据的原因是什么。简单地说，ndarray不只是一块内存和一个dtype，它还有跨度信息，这使得数组能以各种步幅（step size）在内存中移动。更准确地讲，ndarray内部由以下内容组成：&#xA;一个指向数据（内存或内存映射文件中的一块数据）的指针。 数据类型或dtype，描述在数组中的固定大小值的格子。 一个表示数组形状（shape）的元组。 一个跨度元组（stride），其中的整数指的是为了前进到当前维度下一个元素需要“跨过”的字节数。 图A-1简单地说明了ndarray的内部结构。&#xA;例如，一个10×5的数组，其形状为(10,5)：&#xA;In [10]: np.ones((10, 5)).shape Out[10]: (10, 5) 一个典型的（C顺序，稍后将详细讲解）3×4×5的float64（8个字节）数组，其跨度为(160,40,8) —— 知道跨度是非常有用的，通常，跨度在一个轴上越大，沿这个轴进行计算的开销就越大：&#xA;In [11]: np.ones((3, 4, 5), dtype=np.float64).strides Out[11]: (160, 40, 8) 虽然NumPy用户很少会对数组的跨度信息感兴趣，但它们却是构建非复制式数组视图的重要因素。跨度甚至可以是负数，这样会使数组在内存中后向移动，比如在切片obj[::-1]或obj[:,::-1]中就是这样的。&#xA;NumPy数据类型体系# 你可能偶尔需要检查数组中所包含的是否是整数、浮点数、字符串或Python对象。因为浮点数的种类很多（从float16到float128），判断dtype是否属于某个大类的工作非常繁琐。幸运的是，dtype都有一个超类（比如np.integer和np.floating），它们可以跟np.issubdtype函数结合使用：&#xA;In [12]: ints = np.ones(10, dtype=np.uint16) In [13]: floats = np.ones(10, dtype=np.float32) In [14]: np.issubdtype(ints.dtype, np.integer) Out[14]: True In [15]: np.issubdtype(floats.dtype, np.floating) Out[15]: True 调用dtype的mro方法即可查看其所有的父类：&#xA;In [16]: np.float64.mro() Out[16]: [numpy.float64, numpy.floating, numpy.inexact, numpy.number, numpy.</description>
    </item>
    <item>
      <title>附录B-更多关于IPython的内容</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E9%99%84%E5%BD%95b-%E6%9B%B4%E5%A4%9A%E5%85%B3%E4%BA%8Eipython%E7%9A%84%E5%86%85%E5%AE%B9/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E9%99%84%E5%BD%95b-%E6%9B%B4%E5%A4%9A%E5%85%B3%E4%BA%8Eipython%E7%9A%84%E5%86%85%E5%AE%B9/</guid>
      <description>第2章中，我们学习了IPython shell和Jupyter notebook的基础。本章中，我们会探索IPython更深层次的功能，可以从控制台或在jupyter使用。&#xA;B.1 使用命令历史# Ipython维护了一个位于磁盘的小型数据库，用于保存执行的每条指令。它的用途有：&#xA;只用最少的输入，就能搜索、补全和执行先前运行过的指令； 在不同session间保存命令历史； 将日志输入/输出历史到一个文件 这些功能在shell中，要比notebook更为有用，因为notebook从设计上是将输入和输出的代码放到每个代码格子中。&#xA;搜索和重复使用命令历史# Ipython可以让你搜索和执行之前的代码或其他命令。这个功能非常有用，因为你可能需要重复执行同样的命令，例如%run命令，或其它代码。假设你必须要执行：&#xA;In[7]: %run first/second/third/data_script.py 运行成功，然后检查结果，发现计算有错。解决完问题，然后修改了data_script.py，你就可以输入一些%run命令，然后按Ctrl+P或上箭头。这样就可以搜索历史命令，匹配输入字符的命令。多次按Ctrl+P或上箭头，会继续搜索命令。如果你要执行你想要执行的命令，不要害怕。你可以按下Ctrl-N或下箭头，向前移动历史命令。这样做了几次后，你可以不假思索地按下这些键！&#xA;Ctrl-R可以带来如同Unix风格shell（比如bash shell）的readline的部分增量搜索功能。在Windows上，readline功能是被IPython模仿的。要使用这个功能，先按Ctrl-R，然后输入一些包含于输入行的想要搜索的字符：&#xA;In [1]: a_command = foo(x, y, z) (reverse-i-search)`com&amp;#39;: a_command = foo(x, y, z) Ctrl-R会循环历史，找到匹配字符的每一行。&#xA;输入和输出变量# 忘记将函数调用的结果分配给变量是非常烦人的。IPython的一个session会在一个特殊变量，存储输入和输出Python对象的引用。前面两个输出会分别存储在 _（一个下划线）和 __（两个下划线）变量：&#xA;In [24]: 2 ** 27 Out[24]: 134217728 In [25]: _ Out[25]: 134217728 输入变量是存储在名字类似_iX的变量中，X是输入行的编号。对于每个输入变量，都有一个对应的输出变量_X。因此在输入第27行之后，会有两个新变量_27 （输出）和_i27（输入）:&#xA;In [26]: foo = &amp;#39;bar&amp;#39; In [27]: foo Out[27]: &amp;#39;bar&amp;#39; In [28]: _i27 Out[28]: u&amp;#39;foo&amp;#39; In [29]: _27 Out[29]: &amp;#39;bar&amp;#39; 因为输入变量是字符串，它们可以用Python的exec关键字再次执行：</description>
    </item>
    <item>
      <title>审计技能|Python语句（四）：常用查询函数</title>
      <link>https://richfan.site/%E5%AE%A1%E6%8A%80/%E5%AE%A1%E8%AE%A1%E6%8A%80%E8%83%BD-python%E8%AF%AD%E5%8F%A5%E5%9B%9B%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2%E5%87%BD%E6%95%B0/</link>
      <pubDate>Tue, 15 Aug 2023 17:56:00 +0000</pubDate>
      <guid>https://richfan.site/%E5%AE%A1%E6%8A%80/%E5%AE%A1%E8%AE%A1%E6%8A%80%E8%83%BD-python%E8%AF%AD%E5%8F%A5%E5%9B%9B%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2%E5%87%BD%E6%95%B0/</guid>
      <description>1.分组聚合函数（groupby）# 类似SQL的groupby那样的数据透视功能。可以使用pandas库的groupby函数来实现分组聚合操作。&#xA;举例：&#xA;有一个A表，分别有甲项目和乙项目，甲项目连续两年的销售为50万元和54万元，乙项目连续两年的销售额为74万元和56万元。&#xA;现在求甲项目和乙项目的各自销售额之和，具体如下： 代码：&#xA;import pandas as pd ## 创建A表 data = {&amp;#39;项目名称&amp;#39;: [&amp;#39;甲项目&amp;#39;, &amp;#39;甲项目&amp;#39;, &amp;#39;乙项目&amp;#39;, &amp;#39;乙项目&amp;#39;], &amp;#39;销售额&amp;#39;: [50, 54, 74, 56]} df = pd.DataFrame(data) ## 按照“项目名称”进行聚合统计 grouped = df.groupby(&amp;#39;项目名称&amp;#39;) result = grouped.sum() ## 打印结果 print(result) 运行结果：&#xA;销售额 项目名称 乙项目 130 甲项目 104 2.时间转换函数(to_datetime)# 可以使用pandas库的to_datetime函数来实现时间转换操作。&#xA;举例：将分秒的时间转换为日期&#xA;Date Sales 2020-01-01 10:30:00 1000 2020-01-02 15:20:00 1500 2020-01-03 18:40:00 2000 代码：&#xA;import pandas as pd data = pd.DataFrame({&amp;#39;Date&amp;#39;: [&amp;#39;2020-01-01 10:30:00&amp;#39;, &amp;#39;2020-01-02 15:20:00&amp;#39;, &amp;#39;2020-01-03 18:40:00&amp;#39;], &amp;#39;Sales&amp;#39;: [1000, 1500, 2000]}) data[&amp;#39;Date&amp;#39;] = pd.</description>
    </item>
    <item>
      <title>审计技能|Python语句（四）：常用查询函数</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/spider/%E5%AE%A1%E8%AE%A1%E6%8A%80%E8%83%BD-python%E8%AF%AD%E5%8F%A5%E5%9B%9B%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2%E5%87%BD%E6%95%B0/</link>
      <pubDate>Tue, 15 Aug 2023 17:56:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/spider/%E5%AE%A1%E8%AE%A1%E6%8A%80%E8%83%BD-python%E8%AF%AD%E5%8F%A5%E5%9B%9B%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2%E5%87%BD%E6%95%B0/</guid>
      <description>1.分组聚合函数（groupby）# 类似SQL的groupby那样的数据透视功能。可以使用pandas库的groupby函数来实现分组聚合操作。&#xA;举例：&#xA;有一个A表，分别有甲项目和乙项目，甲项目连续两年的销售为50万元和54万元，乙项目连续两年的销售额为74万元和56万元。&#xA;现在求甲项目和乙项目的各自销售额之和，具体如下： 代码：&#xA;import pandas as pd ## 创建A表 data = {&amp;#39;项目名称&amp;#39;: [&amp;#39;甲项目&amp;#39;, &amp;#39;甲项目&amp;#39;, &amp;#39;乙项目&amp;#39;, &amp;#39;乙项目&amp;#39;], &amp;#39;销售额&amp;#39;: [50, 54, 74, 56]} df = pd.DataFrame(data) ## 按照“项目名称”进行聚合统计 grouped = df.groupby(&amp;#39;项目名称&amp;#39;) result = grouped.sum() ## 打印结果 print(result) 运行结果：&#xA;销售额 项目名称 乙项目 130 甲项目 104 2.时间转换函数(to_datetime)# 可以使用pandas库的to_datetime函数来实现时间转换操作。&#xA;举例：将分秒的时间转换为日期&#xA;Date Sales 2020-01-01 10:30:00 1000 2020-01-02 15:20:00 1500 2020-01-03 18:40:00 2000 代码：&#xA;import pandas as pd data = pd.DataFrame({&amp;#39;Date&amp;#39;: [&amp;#39;2020-01-01 10:30:00&amp;#39;, &amp;#39;2020-01-02 15:20:00&amp;#39;, &amp;#39;2020-01-03 18:40:00&amp;#39;], &amp;#39;Sales&amp;#39;: [1000, 1500, 2000]}) data[&amp;#39;Date&amp;#39;] = pd.</description>
    </item>
    <item>
      <title>python数据分析专用数据库，与pandas结合，10倍提速&#43;极致体验</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%93%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8Epandas%E7%BB%93%E5%90%8810%E5%80%8D%E6%8F%90%E9%80%9F&#43;%E6%9E%81%E8%87%B4%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Sat, 12 Aug 2023 17:56:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%93%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8Epandas%E7%BB%93%E5%90%8810%E5%80%8D%E6%8F%90%E9%80%9F&#43;%E6%9E%81%E8%87%B4%E4%BD%93%E9%AA%8C/</guid>
      <description>前言# 你有想过在 pandas 中直接使用 sql吗？我知道许多小伙伴已经知道一些库也可以做到这种体验，不过他们的性能太差劲了(基于sqlite，或其他服务端数据库)。&#xA;今天我要介绍另一个专用于数据分析的列式数据库，性能是其他同体验的库的1000倍以上。可以无缝接入 pandas ，做到了性能与使用体验同时提升。&#xA;这就是今天的主角，duckdb。&#xA;特点# duckdb 是一个单机数据库，你大概率会用它与 sqlite 比较。&#xA;最明显的区别就是，duckdb 是一个分析数据管理系统，而 sqlite 是一个事务型关系数据库。&#xA;这意味着，如果你现在有一大堆数据处理任务，期间无须顾忌会有其他用户插入新数据或删除数据。那么 duckdb 就可以非常好应对这种场景。&#xA;对于我们这种 pandas 老用户，duckdb 支持 pandas 的 dataFrame 通用底层格式(parquet/arrow等)上并行运行查询，而且没有单独的导入步骤。这就是它能保持使用体验的同时，大幅提升查询性能的最大原因。&#xA;我们需要安装这些库&#xA;pip install pandas duckdb -U&#xA;先看一个例子，看看它是如何便捷与 dataframe 交互。&#xA;变量等于表名？# 首先，导入今天需要用到的库&#xA;我们有一大堆销售数据，加载其中一份数据看看： 此时，希望使用 sql 做一些数据查询处理，你认为下面的 sql 简单吗？&#xA;直接使用 dataframe 的变量名作为表名查询 这真的可以做到吗？加上一点点 duckdb 的调用即可：&#xA;duckdb.query 做查询&#xA;df，把查询结果转回 dataframe&#xA;也就是，可以直接使用当前环境下的变量作为表名。&#xA;我知道之前就有其他的库可以做到这种体验，但是必需强调，duckdb 是直接使用 dataframe 的内存数据(因为底层数据格式通用)，因此，这个过程中的输入和输出数据的传输时间几乎可以忽略不计。&#xA;并且，这个过程中，duckdb比 pandas 更快处理数据(多线程)，并且内存使用量也比 pandas 要低得多。&#xA;特别在一些需要分组的数据处理任务上，就算只使用单线程的 duckdb 也会比 pandas 的快两倍。如果是过滤+分组+列投影，会存在 5-8倍 的差异。</description>
    </item>
    <item>
      <title>数据库连接轻松搞定：Python 数据库推荐</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9Apython-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8E%A8%E8%8D%90/</link>
      <pubDate>Sat, 12 Aug 2023 17:56:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E8%BD%BB%E6%9D%BE%E6%90%9E%E5%AE%9Apython-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8E%A8%E8%8D%90/</guid>
      <description>SQLite3：轻巧便捷的数据库连接# 首先，让我们认识一下 SQLite3 这个轻巧便捷的库。它是 Python 中自带的数据库模块，适用于小型应用和快速原型开发。&#xA;让我们来看看 SQLite3 的魔法：&#xA;import sqlite3 ## 连接数据库 conn = sqlite3.connect(&amp;#34;mydatabase.db&amp;#34;) ## 创建表格 cursor = conn.cursor() cursor.execute(&amp;#34;CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, name TEXT, age INTEGER)&amp;#34;) ## 插入数据 cursor.execute(&amp;#34;INSERT INTO users (name, age) VALUES (?, ?)&amp;#34;, (&amp;#34;Alice&amp;#34;, 25)) cursor.execute(&amp;#34;INSERT INTO users (name, age) VALUES (?, ?)&amp;#34;, (&amp;#34;Bob&amp;#34;, 30)) ## 查询数据 cursor.execute(&amp;#34;SELECT * FROM users&amp;#34;) rows = cursor.fetchall() for row in rows: print(row) ## 关闭连接 conn.</description>
    </item>
    <item>
      <title>ExcelToPDF</title>
      <link>https://richfan.site/%E7%A8%8B%E6%8A%80/python/exceltopdf/</link>
      <pubDate>Wed, 23 Feb 2022 17:56:00 +0000</pubDate>
      <guid>https://richfan.site/%E7%A8%8B%E6%8A%80/python/exceltopdf/</guid>
      <description>&lt;h2 id=&#39;excel-to-pdf&#39;&gt;Excel To PDF&lt;a href=&#39;#excel-to-pdf&#39; class=&#39;anchor&#39;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;</description>
    </item>
  </channel>
</rss>
