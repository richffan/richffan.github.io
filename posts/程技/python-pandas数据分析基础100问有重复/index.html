<!DOCTYPE html>
<html lang="zh-CN"><head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
    <meta name="description" content="Python pandas数据分析基础100问(有重复) - https://richfan.site/posts/%E7%A8%8B%E6%8A%80/python-pandas%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80100%E9%97%AE%E6%9C%89%E9%87%8D%E5%A4%8D/">
    <meta name="author" content="richfan - https://richfan.site/">
    
    <meta name="msvalidate.01" content="B46311949B856F2A7015F366FB3CE878" />
    <title>Python pandas数据分析基础100问(有重复)</title>
    <link rel="icon" type="image/png" href="/favicon.ico">
    
    <link rel="stylesheet" href="https://richfan.site/style.min.d252ad53a5e6b2ae6b8c6c1661107189be3668e36c8dd61697bbe008595a7e04.css">
    
    <script type="text/javascript" src="/main.js" defer></script>
    
</head>
<body class="active-animate cool">
        <div id="header"><div class="container-header">
    <div id="vars" class="container-vars" style="display: none;">
	{
		"isSingleColumnOfPostList": true,
		"hasFoldAllCodeBlocks": false,
		"svgColor": "",
		"en": false,
		"dark": true
	}
</div>
    <h1 class="title">
        
            Python pandas数据分析基础100问(有重复)
            
        
    </h1>

    <div class="container-breadcrumb-nav">
    
    <div class="breadcrumb-nav-bar">
        <div><a href="/"><svg t="1656411084410" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2954" width="16" height="16"><path d="M947.5 390.6l-377-290c-34.5-26.5-82.6-26.5-117.1 0l-377 290c-14 10.8-16.6 30.9-5.9 44.9 10.8 14 30.9 16.6 44.9 5.9l28.5-21.9V768c0 88.2 71.8 160 160 160h80c35.3 0 64-28.7 64-64V640c0-17.6 14.4-32 32-32h64c17.6 0 32 14.4 32 32v224c0 35.3 28.7 64 64 64h80c88.2 0 160-71.8 160-160V419.4l28.5 21.9c5.8 4.5 12.7 6.6 19.5 6.6 9.6 0 19.1-4.3 25.4-12.5 10.8-13.9 8.2-34-5.8-44.8zM816 768c0 52.9-43.1 96-96 96h-80V640c0-52.9-43.1-96-96-96h-64c-52.9 0-96 43.1-96 96v224h-80c-52.9 0-96-43.1-96-96V370.2l284.5-218.8c11.5-8.8 27.5-8.8 39 0L816 370.2V768z" fill="#6c757d" p-id="2955"></path></svg></a></div>
        <div><a href="/nav"><svg t="1656411531924" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5827" width="16" height="16"><path d="M849.59197473 125.23018519L139.22930586 391.72854662a23.35052669 23.35052669 0 0 0-14.95414244 21.65490745c-0.12257519 9.70384955 5.61801843 18.46795771 14.40255493 22.04306141l318.42928099 129.25528056 119.51057092 320.39047893c3.06437293 8.23295069 10.35758221 13.89182751 18.7335381 14.87242563l2.7170774 0.14300521a22.79893918 22.79893918 0 0 0 21.20546682-15.36272638l259.51158924-729.54564933a23.8612558 23.8612558 0 0 0-5.31158128-24.55584682 22.3290685 22.3290685 0 0 0-23.9021142-5.43415649zM793.65694081 211.64552314l-196.63064161 552.75171747-91.91077952-246.37564122-253.62799211-102.96295445 542.16941324-203.4131218z" p-id="5828" fill="#6c757d"></path></svg></a></div>
        <div><a href="/search"><svg t="1656411627509" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1730" width="14" height="14"><path d="M469.333333 85.333333c211.968 0 384 172.032 384 384s-172.032 384-384 384-384-172.032-384-384 172.032-384 384-384z m0 682.666667c164.992 0 298.666667-133.674667 298.666667-298.666667 0-165.034667-133.674667-298.666667-298.666667-298.666666-165.034667 0-298.666667 133.632-298.666666 298.666666 0 164.992 133.632 298.666667 298.666666 298.666667z m362.026667 3.029333l120.704 120.661334-60.373333 60.373333-120.661334-120.704 60.330667-60.330667z" p-id="1731" fill="#6c757d"></path></svg></a></div>
        <div><a href="/posts"><svg t="1656411724198" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5655" width="12" height="12"><path d="M811.705761 1024H212.294239c-93.1199 0-174.823046-87.570975-174.823046-187.387854V162.322018C37.471193 69.776145 112.604921 0 212.294239 0H596.190595l7.015883 5.93161c111.74388 95.479788 185.857116 170.741078 279.614824 266.093304 29.65805 30.040735 61.165743 62.122454 96.436499 97.393211l7.271006 7.334787v459.859234c-0.063781 99.816879-81.703145 187.387854-174.823046 187.387854zM212.294239 49.94033c-72.391155 0-124.882716 47.261538-124.882716 112.381688v674.290128c0 71.94469 59.507443 137.383743 124.882716 137.383743h599.411522c65.311492 0 124.882716-65.439053 124.882716-137.383743V397.417876c-32.528184-32.464404-61.73977-62.250016-89.356836-90.377328-90.951355-92.418312-163.278729-165.957521-269.601245-257.163999H212.294239z" fill="#6c757d" p-id="5656"></path><path d="M936.588477 449.526752h-212.326129c-99.753099 0-187.324073-81.703145-187.324073-174.823046V49.94033a25.002055 25.002055 0 0 1 49.94033 0v224.763376c0 65.311492 65.502834 124.882716 137.383743 124.882716h212.326129a25.002055 25.002055 0 1 1 0 49.94033z" fill="#6c757d" p-id="5657"></path></svg></a></div>
        <div><a href="/archive"><svg t="1656411795742" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="7334" width="12" height="12"><path d="M884.224 522.24H504.32V141.824c0-16.896-13.824-30.72-30.72-30.72-120.32 0-233.472 47.616-317.952 134.144S26.112 445.952 29.184 566.784c2.56 114.688 49.152 222.72 131.072 304.128 81.92 81.408 189.952 128 304.64 130.56h10.24c117.76 0 227.84-45.568 312.32-128.512 86.528-85.504 133.632-199.68 132.608-321.024-0.512-2.048-1.536-29.696-35.84-29.696z m-140.288 307.712c-74.752 73.728-173.056 112.64-277.504 110.592-205.824-4.608-370.688-169.472-375.296-374.784-3.072-104.448 35.84-202.752 108.544-277.504 65.536-67.072 151.552-107.52 243.712-114.688v378.88c0 16.896 13.824 30.72 30.72 30.72 129.024 0 311.296 0 382.976 0.512-6.144 93.184-46.08 179.712-113.152 246.272z" fill="#6c757d" p-id="7335"></path><path d="M603.136 11.264c-8.192-0.512-15.872 3.072-22.016 8.704-5.632 5.632-9.216 13.824-9.216 22.016v378.88c0 16.896 13.824 30.72 30.72 30.72h378.88c16.896 0 30.72-13.824 30.72-30.72 0-223.744-183.808-407.552-409.088-409.6z m30.208 378.88V74.24c167.424 16.384 301.056 150.016 315.904 315.904h-315.904z" fill="#6c757d" p-id="7336"></path></svg></a></div>
        <div id="light-dark" style="cursor: pointer;"><a><svg t="1656411842215" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5086" width="12" height="12"><path d="M1007.492874 384.513055c-8.795694-34.58307-21.189627-67.666874-36.682043-99.05151-2.698679-5.397358-10.894667-3.498287-10.894666 2.598728v0.299853c0 32.484098-6.896624 63.868734-19.890263 92.554691-10.694764 23.488501-25.487523 45.077933-43.978471 64.068635-41.779547 42.679107-99.05151 66.967217-158.722299 67.26707-61.869712 0.299853-119.941284-24.188159-162.920244-68.966238-40.280281-41.979449-62.56937-98.251902-62.269516-156.323473 0.399804-59.270984 23.588452-114.94373 65.567901-156.823229 19.59041-19.59041 42.179351-35.082826 66.667364-46.077443C672.956643 71.166451 704.041426 64.469729 736.125719 64.469729h1.299364c6.097015 0 8.096037-8.096037 2.598728-10.794715C708.739126 37.982696 675.655322 25.488812 641.172203 16.493216 599.492607 5.598549 555.714038-0.098662 510.536154 0.001289 222.37722 0.700947-7.41029 237.38508 0.185992 525.444064c7.096526 271.667008 225.889418 490.559851 497.456474 497.856279 287.559228 7.796183 524.14341-220.891864 525.842579-508.551044 0.299853-44.977981-5.297407-88.656599-15.992171-130.236244z m-83.15929 301.552378c-22.588942 53.27392-54.873137 101.250434-95.953027 142.330323-41.179841 41.179841-89.056403 73.464036-142.330324 95.953027-55.172991 23.288599-113.744317 35.182777-174.314666 35.182777s-119.141675-11.794226-174.314666-35.182777c-53.27392-22.588942-101.250434-54.873137-142.330323-95.953027-41.179841-41.179841-73.464036-89.056403-95.953027-142.330323C75.749001 630.892442 63.954774 572.221164 63.954774 511.750767s11.794226-119.141675 35.182777-174.314666c22.588942-53.27392 54.873137-101.250434 95.953027-142.330323 41.179841-41.179841 89.056403-73.464036 142.330323-95.953027C392.593892 75.7642 451.26517 63.969974 511.735567 63.969974c13.99315 0 27.886348 0.599706 41.679596 1.89907C489.246577 118.643209 448.266638 198.704016 448.266638 288.360126c0 159.022152 128.836929 287.859081 287.859081 287.859081 89.156354 0 168.817357-40.580134 221.691473-104.149015 1.099462 13.09359 1.699168 26.387082 1.699168 39.680575 0 60.470397-11.794226 119.141675-35.182776 174.314666z" p-id="5087" fill="#6c757d"></path></svg></a></div>
        
    </div>

    
</div>

            <div id="toc">📜</div>
        
    
    
</div>
</div>
        <div id="content">















<div class="container-main 
     container-page 
">

    <div class="desc">
        
        <span>
            
            <svg t="1656736000388" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="7409" width="12" height="12"><path d="M524.885333 338.986667L200.362667 663.466667c-17.28 15.274667-27.989333 36.693333-29.696 56.234666v133.76l130.730666 0.085334c22.784-1.621333 43.989333-12.245333 61.013334-31.701334l322.688-322.645333-160.213334-160.213333z m60.373334-60.330667l160.170666 160.213333 102.144-102.144a19.712 19.712 0 0 0 0-27.861333L715.093333 176.426667a19.456 19.456 0 0 0-27.605333 0L585.258667 278.613333zM701.312 85.333333c27.946667 0 54.741333 11.136 74.282667 30.848l132.309333 132.309334a105.045333 105.045333 0 0 1 0 148.565333L424.874667 879.957333c-29.824 34.346667-72.106667 55.466667-120.448 58.794667H85.333333v-42.666667l0.128-179.84c3.626667-44.970667 24.576-86.826667 56.448-114.944l485.12-485.034666A104.789333 104.789333 0 0 1 701.269333 85.333333z" p-id="7410" fill="#adb5bd"></path></svg>
            2023-09-25&nbsp;
        </span>
        <span>
            
            <svg t="1656737270708" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23838" width="11" height="11"><path d="M824.264 95.36c0-23.859 25.043-44.16 48.902-44.16s49.714 20.301 49.714 44.16v190.08c0 23.859-19.054 52.868-42.913 52.868h-190.08c-23.859 0-46.696-25.96-46.696-49.819s22.55-46.249 46.409-46.249h82.025C702.344 175.534 610.22 155.853 512 155.853c-206.775 0-360.398 149.372-360.398 356.147 0 206.775 153.623 358.23 360.398 358.23 206.775 0 357.467-151.455 357.467-358.23 0-23.859 23.634-50.706 53.413-50.706 29.78 0 49.92 26.847 49.92 50.706 0 254.493-206.307 460.8-460.8 460.8-254.493 0-460.8-206.307-460.8-460.8C51.2 257.507 257.507 51.2 512 51.2c122.4 0 226.684 33.296 312.264 117.369 0.358 0.351 0.358-24.052 0-73.209z" p-id="23839" fill="#adb5bd"></path></svg>
            2023-09-25&nbsp;&nbsp;&nbsp;
        </span>
        <span>
            
            <svg t="1656737548689" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="33866" width="12" height="12"><path d="M832.038608 64.662657H192.030028C121.255125 64.662657 63.940169 121.98845 63.940169 192.694717v446.793671C63.940169 710.205493 121.255125 767.643272 192.030028 767.643272h133.353183a63.940169 63.940169 0 0 1 55.219742 31.576328l76.099638 129.83828c12.358154 21.093031 33.790754 31.626903 55.216129 31.626903s42.832688-10.544709 55.198067-31.619678l76.222461-129.870792a63.940169 63.940169 0 0 1 55.212517-31.551041h133.54103c70.576219 0 127.732228-57.289669 127.732227-127.800865V192.391272C959.825022 121.85479 902.643727 64.662657 832.038608 64.662657zM895.884854 639.842407A63.85347 63.85347 0 0 1 832.092795 703.703103h-133.54103a127.753903 127.753903 0 0 0-110.349172 63.09847l-76.222461 129.856342a0.274545 0.274545 0 0 1 0-0.050574h-0.032512s-0.021675 0.061411-0.032512 0.061412l-76.1466-129.85273A127.804477 127.804477 0 0 0 325.383211 703.703103H192.030028A64.207489 64.207489 0 0 1 127.880338 639.488388V192.694717A64.102729 64.102729 0 0 1 192.030028 128.602826h640.00858A63.799284 63.799284 0 0 1 895.884854 192.391272v447.451135z" fill="#adb5bd" p-id="33867"></path><path d="M608.154093 288.092004A31.970084 31.970084 0 0 0 576.184009 320.062089v160.078006l-134.650049-179.278119A31.970084 31.970084 0 0 0 384.002258 320.062089v255.760676a31.970084 31.970084 0 0 0 63.940169 0v-159.958796l134.650048 179.274507a31.970084 31.970084 0 0 0 57.531703-19.200113V320.062089a31.970084 31.970084 0 0 0-31.970085-31.970085z" fill="#adb5bd" p-id="33868"></path></svg>
            8727 字</span>&nbsp;
        <span>
            
            <svg t="1656737462334" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="32892" width="12" height="12"><path d="M512 74.666667C270.933333 74.666667 74.666667 270.933333 74.666667 512S270.933333 949.333333 512 949.333333 949.333333 753.066667 949.333333 512 753.066667 74.666667 512 74.666667z m0 810.666666c-204.8 0-373.333333-168.533333-373.333333-373.333333S307.2 138.666667 512 138.666667 885.333333 307.2 885.333333 512 716.8 885.333333 512 885.333333z" p-id="32893" fill="#adb5bd"></path><path d="M695.466667 567.466667l-151.466667-70.4V277.333333c0-17.066667-14.933333-32-32-32s-32 14.933333-32 32v238.933334c0 12.8 6.4 23.466667 19.2 29.866666l170.666667 81.066667c4.266667 2.133333 8.533333 2.133333 12.8 2.133333 12.8 0 23.466667-6.4 29.866666-19.2 6.4-14.933333 0-34.133333-17.066666-42.666666z" p-id="32894" fill="#adb5bd"></path></svg>
            18 分钟</span>
            <div class="container-ctgtag">
	<div class="taxonomy">
		
		<div class="ctg">
			
			
			<a href="/categories/%E7%A8%8B%E6%8A%80">程技</a>
			
		</div>
		<div class="tag">
			
			 - 
			
			<a href="/tags/pandas">pandas</a>
			
		</div>
	</div>
</div>
        
    </div>
    
    <div class="toc">
        
        <div class="page-operation">
            <div><a href="#"><img src="/imgs/icons/arrow-up-circle.svg" alt=""></a></div>
            <div><a href="https://richfan.site/posts/%E7%A8%8B%E6%8A%80/git/"><img src="/imgs/icons/arrow-left-circle.svg" alt=""></a></div>
            <div><a href="https://richfan.site/posts/%E7%A8%8B%E6%8A%80/emoji/"><img src="/imgs/icons/arrow-right-circle.svg" alt=""></a></div>
        </div>
        
        <nav id="TableOfContents"></nav>
    </div>

    <div class='content  content '>
        <p>题目来自B站上看的一个讲爬虫的老师发的视频，不过代码没完全照那人的来，由于在平板上写的代码，就没有执行结果，感兴趣自行到B站搜原视频。</p>
<pre tabindex="0"><code>import pandas as pd
</code></pre><p>1、将list转为dataframe</p>
<pre tabindex="0"><code>ls = [(&#34;join&#34;, 25, &#34;male&#34;), (&#34;lisa&#34;, 29, &#34;female&#34;), (&#34;david&#34;, 27, &#34;male&#34;)``df = pd.DataFrame(ls, columns=[&#34;name&#34;, &#34;age&#34;, &#34;gender&#34;])``display(df)
</code></pre><p>2、从csv文件中读取数据</p>
<pre tabindex="0"><code>df = pd.read_csv(&#34;filenpath&#34;, encoding=&#34;utf8&#34;)``# filepath_or_buffer: filepath 文件路径``# usecols: 需要读取的行列表``# nrows: 读取的行数``# na_values: 空值``# encoding: 编码格式
</code></pre><p>3、将dataframe导入到mysql</p>
<pre tabindex="0"><code>from sqlalchemy import create_engine``from sqlclchemy.type import *``df = pd.DataFrame() # 数据集``# 创建引擎``conn = create_engine(&#34;mysql+mysqlconnector://username:password@127.0.0.1:3306/db_name&#34;)``# 写入到数据库``df.to_sql(&#34;table_name&#34;, engine)
</code></pre><p>4、查看一个dataframe的行数、列数</p>
<pre tabindex="0"><code># 行``df.shape[0]``# 列``df.shape[1]
</code></pre><p>5、查看dataframe的列名</p>
<pre tabindex="0"><code>df.columns # serise格式``df.columns.tolist() # list格式
</code></pre><p>6、查看dataframe索引</p>
<pre tabindex="0"><code>df.index # series格式``df.index.tolist()
</code></pre><p>7、查看pandas库的版本号</p>
<pre tabindex="0"><code>pd.__version__
</code></pre><p>8、从csv文件里读取数据，并创建一个dataframe</p>
<pre tabindex="0"><code>df = pd.read_csv(&#34;filepath&#34;, encoding=&#39;utf8&#39;)
</code></pre><p>9、查看dataframe的列的数据类型</p>
<pre tabindex="0"><code>df.dtypes
</code></pre><p>10、查看dataframe摘要统计描述信息</p>
<pre tabindex="0"><code>df.describe() # count/mean/std/min/max 1-4分位数，1-10分位数``# include: 统计哪些列，默认为None，全部``# exclude: 排除列``# percentiles: 分位点,默认为None,4分位
</code></pre><p>11、dataframe提取行</p>
<pre tabindex="0"><code>df.loc[index_name] # 单行``df.loc[index_name1, index_name2] # 多行``df.iloc[start_index: end_index] # 连续多行，不包含end
</code></pre><p>12、dataframe提取列</p>
<pre tabindex="0"><code>df[&#34;col_name&#34;] # 单列``df[[&#34;col_1&#34;, &#34;col_2&#34;, ....]] # 多列``df.iloc[:, col_index] # 单列``df.iloc[:, col_start_index: col_end_index] # 按列索引取 连续多列
</code></pre><p>13、选择datafram的行和列</p>
<pre tabindex="0"><code>df.loc[[indexName1, indexName2..], [colName1, colName2...]]  # 按行列名提取``   ``df.iloc[[startIndex: endIndex], [colStartIndex: colEndIndex]] # 按行列索引提取，不包括end
</code></pre><p>14、筛选dataframe的行</p>
<pre tabindex="0"><code># 使用列条件筛选行``df[df[列名条件]] # 单条件``df[(条件1) &amp; (条件2)] # 多条件，每一个单条件用()包起来，连接符号：&amp;-与，|-或，～非``# 示例：筛选出年龄小于等于30，且收入大于等于30万的男性``df[(df[&#34;age&#34;]&lt;=30) &amp; (df[&#34;income&#34;]&gt;=300000) &amp; df[&#34;gender&#34;]==&#34;male&#34;]
</code></pre><p>15、筛选dataframe的行和列</p>
<pre tabindex="0"><code>df[(条件1) &amp; (条件2)][[colName1, colName2....]] # 筛选行之后再选择需要的列``df.loc[行筛选条件, [colName1, colName2]] # 使用列进行行条件筛选，同时限定输出列
</code></pre><p>16、根据某一列的值对一个dataframe进行排序</p>
<pre tabindex="0"><code>df.sort_values(by=[&#34;col1&#34;, &#34;col2&#34;], ascending=True) # 默认升序
</code></pre><p>17、对dataframe进行数据透视操作，即实现excel中的数据透视表功能</p>
<pre tabindex="0"><code>df.pivot_table(index=&#39;行索引&#39;, columns=&#39;列索引&#39;, values=&#34;统计列&#34;, aggfunc=&#39;函数名&#39;)``# aggfunc 支持 sum/mean/count/min/max等
</code></pre><p>18、对dataframe进行聚合操作</p>
<pre tabindex="0"><code>df.groupby(by=[&#34;索引列1&#34;, &#34;索引列2&#34;])[&#39;统计列&#39;].agg([&#34;函数1&#34;, &#34;函数2&#34;, &#34;函数3&#34;])
</code></pre><p>19、对多个dataframe实现合并操作</p>
<pre tabindex="0"><code># 纵向合并` `pd.merge(df_left, df_right, on=[&#34;合并列1&#34;, &#34;合并列2&#34;], how=&#34;inner or left or right or outer&#34;)``# 横向合并``pd.concat([df_1, df_2, df_3]) # 常用于拥有相同格式的多个数据集
</code></pre><p>20、删除dataframe中的一列或多列数据</p>
<pre tabindex="0"><code>df.drop(columns=[&#34;需要删除的列&#34;], inplace=True) # 默认是生成一个新的数据集，inplace=False``   ``df.dorp(subset=[&#34;需要删除的列&#34;], axis=1, inplace=True)
</code></pre><p>21、向dataframe中添加一行数据</p>
<pre tabindex="0"><code>df.iloc[df.shape[0]] = index_array
</code></pre><p>22、删除dataframe中的一行或多行数据</p>
<pre tabindex="0"><code>df.drop(subset=[1, 3], axis=0, inplace=True)
</code></pre><p>23、使用索引选择dataframe中某个范围内的行</p>
<pre tabindex="0"><code>df[1: 4] # 提取第一行到第四行
</code></pre><p>24、使用某一列选择dataframe中某个范围内的行</p>
<pre tabindex="0"><code>df.set_index(&#34;name&#34;).loc[&#34;start_indexName&#34;: &#34;end_indexName&#34;] # 连续索引名``# 不连续行，在列表中用逗号分隔即可
</code></pre><p>25、在dataframe中按特定条件取行</p>
<pre tabindex="0"><code>df[df[&#34;name&#34;] == &#34;小杨&#34;] # 单条件、单取值``df[df[&#34;name&#34;] in [&#34;小杨&#34;, &#34;小李&#34;]] # 单条件、多取值``df[(df[&#34;name&#34;] in [&#34;小杨&#34;, &#34;小李&#34;]) &amp; (df[&#34;age&#34;] &gt;= 30)] # 多条件
</code></pre><p>26、修改dataframe的列名</p>
<pre tabindex="0"><code># 修改``df.rename(columns={&#34;原列名&#34;: &#34;修改后的列名&#34;}, inplace=True)``# 重新设置``df.columns = [新的列名数组]
</code></pre><p>27、计算dataframe中某一列的总和</p>
<pre tabindex="0"><code>df[&#34;colName&#34;].sum()
</code></pre><p>28、计算dataframe中某一列的平均值</p>
<pre tabindex="0"><code>df[&#34;col_name&#34;].mean() # 返回浮点类型
</code></pre><p>29、计算dataframe中某一列的中位数</p>
<pre tabindex="0"><code>df[&#34;col_name&#34;].median() # 返回浮点类型
</code></pre><p>30、计算dataframe中某一列的标准差</p>
<pre tabindex="0"><code>df[&#34;col_name&#34;].std()
</code></pre><p>31、计算dataframe中某一列的方差</p>
<pre tabindex="0"><code>df[&#34;col_name&#34;].var()
</code></pre><p>32、计算dataframe中某一列的最大值和最小值</p>
<pre tabindex="0"><code>df[&#34;col_name&#34;].max()``df[&#34;col_name&#34;].min()
</code></pre><p>33、查找dataframe某个单元格</p>
<pre tabindex="0"><code>df.loc[row, col]
</code></pre><p>34、dataframe重命名列名</p>
<pre tabindex="0"><code>df.rename(columns={&#34;key&#34;: &#34;value&#34;}, inplace=True)
</code></pre><p>35、替换dataframe中的特定值</p>
<pre tabindex="0"><code># 单列-1``df[&#34;col_name&#34;].replace(to_replace=&#34;replace_str&#34;, value=&#34;str_new&#34;, regex=True)``# 单列-2``df[&#34;col_name&#34;].map(lambda x: str(x).replace(&#34;replace_str&#34;, &#34;str_new&#34;))
</code></pre><p>36、如何将dataframe中的特定制替换成缺失值</p>
<pre tabindex="0"><code>df = df.replace(replace_value, np.nan) # 空值：np.nan pd.NaT
</code></pre><p>37、将dataframe中的空值进行填充</p>
<pre tabindex="0"><code>df.fillna(value, inplace=True)``# value = -999, 直接填充值``# value = &#34;ffill&#34;, 使用上一个非空值进行填充``# value = &#34;bfill&#34;, 使用后一个非空值进行填充``# value = {&#34;col1&#34;: value1, &#34;col2&#34;: value2}, 传入字典，不同列填充不同的值
</code></pre><p>38、删除dataframe中的缺失值</p>
<pre tabindex="0"><code>df.dropna(subset=[&#34;col1&#34;, &#34;col2&#34;], how=&#39;any&#39;, axis=0, inplace=True)``# subset: 用来判断是否删除的列``# axis: 0-删除行, 1-删除列``# how: any-一旦存在空值就删除, all-全为空时删除``# thresh: 0-1的浮点数，空值占比大于一定比例时删除
</code></pre><p>39、在dataframe中使用聚合函数</p>
<pre tabindex="0"><code>df.groupby(by=[&#34;col1&#34;, &#34;col2&#34;]).mean()``# 也可以使用count/sum等函数
</code></pre><p>40、在pandas中创建一个空的数据帧</p>
<pre tabindex="0"><code>df = pd.DataFrame()
</code></pre><p>41、在pandas中进行分组、聚合</p>
<pre tabindex="0"><code>df.groupby(by=[&#34;col1_groupby&#34;, &#34;col2_groupby&#34;])[&#34;col1_calculate&#34;, &#34;col2_calculate&#34;].agg(&#34;func1&#34;, &#34;func2&#34;[, ....])
</code></pre><p>42、对dataframe中的数据进行类型转换</p>
<pre tabindex="0"><code>df[&#34;col_name&#34;] = df[&#34;col_name&#34;].astype(np.int)
</code></pre><p>43、如何使用pandas中的迭代循环方法</p>
<pre tabindex="0"><code>for index,row in df.iterrows():`    `print(index, row)
</code></pre><p>44、如何使用pandas中的交叉表(列联表)</p>
<pre tabindex="0"><code>pd.crosstab(df[&#34;col_index&#34;], df[&#34;col_feature&#34;]) # 默认是统计次数
</code></pre><p>45、如何在pandas中使用重塑(reshape)数据？</p>
<pre tabindex="0"><code>df.pivot(index=&#34;col_index&#34;, columns=&#34;col_feature&#34;, values=&#34;col_calculate&#34;)
</code></pre><p>46、如何在pandas中使用变因子(factorize)函数</p>
<pre tabindex="0"><code>df[&#34;new&#34;] = pd.factorize(df[&#34;class&#34;]) # 相当于是把字符串类别变量进行数值化
</code></pre><p>47、在dataframe中创建随机日期列</p>
<pre tabindex="0"><code>start_date = &#39;2023-01-01&#39;``end_date = &#39;2023-07-27&#39;``data_range = pd.date_range(start=start_date, end=end_date)``   ``# size=df.shape[0] 即可创建一个跟dataframe等长的列``df[&#34;random_date&#34;] = pd.Series(np.random.choice(date_range, size=df.shape[0]))
</code></pre><p>48、如何在pandas中使用字符串函数</p>
<pre tabindex="0"><code># to_uppercase 字符串中的字母转为大写``# to_lowercase 字符串中的字母转为小写``# strip 去除字符串两侧的空格``# replace 将字符串中的一个子字符串替换成另外一个子字符串``# contains 判断字符串是否包含给定的子字符串``# startwith 判断字符串是否以给定字符串开头``# endwith 判断字符串是否以给定字符串结尾``# split 切分字符串``   ``df[&#39;col_name&#39;] = df[&#39;col_name&#39;].str.strip() # 对某一列去除空格``df[&#39;col_name&#39;] = df[&#39;col_name&#39;].str.strip().str.to_lowercase() # 对某一列去除空格，然后字母转小写
</code></pre><p>49、如何在dataframe中使用字符串拆分函数</p>
<pre tabindex="0"><code>df[[&#39;col_1&#39;, &#39;col2&#39;]] = df[&#39;col_to_split&#39;].str.split(&#34;用来切分的字符串&#34;, expand=True)
</code></pre><p>50、如何对dataframe进行标准化处理</p>
<pre tabindex="0"><code>import pandas as pd``from sklearn.preprocessing import StandardScaler``   ``df_new = StandardScaler().fit_transform(df)
</code></pre><p>51、如何对dataframe进行归一化处理</p>
<pre tabindex="0"><code>import sklearn.preprocessing import MinMaxScaler``df_new = MinMaxScaler().fit_transform(df)
</code></pre><p>52、在pandas中使用数据透视表进行数据汇总</p>
<pre tabindex="0"><code>pd.pivot_table(df, values=&#34;计算列&#34;, index=&#39;索引列&#39;, columns=&#34;特征列&#34;, agg=&#34;func_name&#34;)``# 跟pivot也没有太大差别
</code></pre><p>53、在dataframe中使用groupby进行数据汇总</p>
<pre tabindex="0"><code>df.groupby(by=[&#34;col_name1&#34;, &#34;col_name2&#34;]).sum() # .mean .max .std
</code></pre><p>54、如何在Series中使用rolling函数进行移动窗口统计？</p>
<pre tabindex="0"><code>import pandas as pd``import numpy as np``se = pd.Series(np.random.randn(10))``&gt;&gt;&gt; se``0   -0.974864``1    1.916511``2    0.760756``3    0.110363``4   -0.137077``5    0.186016``6   -0.759734``7   -1.529321``8   -1.571819``9    0.123134``   ``se_rolling = se.rolling(window=3).mean()``&gt;&gt;&gt; se_rolling` `0         NaN``1         NaN``2    0.567468``3    0.929210``4    0.244681``5    0.053101``6   -0.236932``7   -0.701013``8   -1.286958``9   -0.992669``   ``计算逻辑：由于index为0、1时，由于不足移动数量，结果为NaN``index2 =（index0+index1+index2 ）/ 3``index3 =（ index1+index2+index3）/ 3``   ``# 语法``DataFrame.rolling(`    `window, # 表示时间窗的大小，数值表示计算统计量的观测值的数量即向前几个数据`    `min_periods=None, # 每个窗口最少包含的观测值数量，小于这个值的窗口结果为NA，值可以是int，默认None。`    `center=False, # 把窗口的标签设置为居中。布尔型，默认False，居右`    `win_type=None, # 窗口的类型。截取窗的各种函数。字符串类型，默认为None。`    `on=None, # 可选参数。对于dataframe而言，指定要计算滚动窗口的列。值为列名。`    `axis=0, # 默认为0，即对列进行计算`    `closed=None # 定义区间的开闭，默认是左开右闭的即默认为right,默认是左开右闭的即默认为right`    `)
</code></pre><p>55、在pandas中使用shift函数进行时间序列处理</p>
<pre tabindex="0"><code>import pandas as pd``import numpy as np``import datetime``   ``# 创建一个时间数组``date_range = pd.date_range(start=&#39;2023-01-01&#39;, end=&#39;2023-07-28&#39;, periods=10)``# 创建一个Serise``se = pd.Series(np.random.randn(10), index=date_range)``&gt;&gt;&gt; se``2023-01-01 00:00:00    0.294050``2023-01-24 02:40:00   -0.324300``2023-02-16 05:20:00    0.345552``2023-03-11 08:00:00   -1.519163``2023-04-03 10:40:00    0.446149``2023-04-26 13:20:00    1.109210``2023-05-19 16:00:00    1.061693``2023-06-11 18:40:00   -1.417034``2023-07-04 21:20:00   -0.218537``2023-07-28 00:00:00   -0.365196``   ``# shift数据前滞 或 后滞``result = se.shift(periods=3, freq=datetime.timedelta(-3))``&gt;&gt;&gt; result``2022-12-23 00:00:00    0.294050``2023-01-15 02:40:00   -0.324300``2023-02-07 05:20:00    0.345552``2023-03-02 08:00:00   -1.519163``2023-03-25 10:40:00    0.446149``2023-04-17 13:20:00    1.109210``2023-05-10 16:00:00    1.061693``2023-06-02 18:40:00   -1.417034``2023-06-25 21:20:00   -0.218537``2023-07-19 00:00:00   -0.365196``   ``# DataFrame.shift(periods=1, freq=None, axis=0)``# periods可以理解为移动幅度的次数，负数表示前滞，正数表示后滞。``# freq为None时，移动的是其他数据的值，即移动periods*1个单位长度。可以设为一个timedelta对象。适用于索引为时间序列数据时。``# axis默认为0，表示对列操作。如果为行则表示对行操作。
</code></pre><p>56、如何在pandas中使用set_index函数设置索引</p>
<pre tabindex="0"><code>df.set_index(keys=[&#39;a&#39;, &#39;b&#39;]) # 将a\b两列设置为索引``   ``# set_index(keys, drop=True, inplace=False)``# drop: 是否删除原本的列，默认True-删除``# inplace: 是否原地修改，默认False-否
</code></pre><p>57、如何在pandas中使用reset_index函数重置索引</p>
<pre tabindex="0"><code>df.reset_index() # 什么都不传入，默认把所有层级的索引重置为新的字段``   ``# reset_index(level=None, drop=False, inplace=False)``# level: 需要重置的索引层级``# drop: 是否删除，默认False``# inplace: 是否原地操作，默认False
</code></pre><p>58、如何在pandas中使用map进行数据操作</p>
<pre tabindex="0"><code># map函数用于列操作``# 数据映射``mapping_dict = {&#34;male&#34;:0, &#34;female&#34;:1}``df[&#34;gender&#34;] = df[&#34;gender&#34;].map(mapping_dict)``   ``# 更常见的操作是向map传入一个函数``def mapping(x):`    `mapping_dict = {&#34;male&#34;:0, &#34;female&#34;:1}`    `return mapping_dict[x]``df[&#34;gender&#34;] = df[&#34;gender&#34;].map(mapping)``   ``# 传入匿名函数``df[&#34;gender&#34;] = df[&#34;gender&#34;].map(lambda x: lambda 1 if x==&#34;female&#34; else 0)
</code></pre><p>59、如何在pandas中使用apply函数进行元素级函数应用</p>
<pre tabindex="0"><code># apply函数用于单元格级的操作``def multiply_by_2(x)`    `return x*2``df_new = df.apply(multiply_by_2) # df中的每一个元素都乘以2``   ``# 个人比较常用的操作：``df_new = df.groupby(groupby).apply(lambda df: pd.Series({`    `&#39;cnt&#39;: df.shape[0],`    `&#39;bad_cnt&#39;: df[label].sum(),`    `# 当标签类型只有0、1的时候，可以使用均值计算坏账率`    `&#39;bad_rate&#39;: df[label].mean(),`    `&#39;begin_date&#39;: df[apply_time_label].min(),`    `&#39;end_date&#39;: df[apply_time_label].max()})).reset_index()`    `# 造特征``df[&#34;col_new&#34;] = df.apply(lambda x: x[&#34;col1&#34;] if x[&#34;col&#34;]&gt;=100 else x[&#34;col2&#34;], axis=1)
</code></pre><p>60、如何在pandas中使用agg函数进行分组聚合操作</p>
<pre tabindex="0"><code>df.groupby([&#39;col_1&#39;, &#34;col_2&#34;]).agg({&#34;col3&#34;:&#34;sum&#34;, &#34;col4&#34;:&#34;mean&#34;})
</code></pre><p>61、如何在pandas中使用transform函数进行分组变换操作</p>
<pre tabindex="0"><code># 通过分组后的计算，取到对分组结果进行赋值的效果``df[&#34;col_new&#34;] = df.groupby(&#39;col1&#39;)[&#39;col_calculate&#39;].transform(lambda x: x.mean())
</code></pre><p>62、如何在pandas中使用stack和unstack函数进行数据透视操作</p>
<pre tabindex="0"><code># stack: 列转行``import pandas as pd``import numpy as np``df = pd.DataFrame({&#34;name&#34;: [&#39;alice&#39;, &#39;bob&#39;, &#39;charlie&#39;],`        `&#34;year&#34;: [2020, 2021, 2022],`        `&#34;age&#34;: [20, 30, 40]})``df.set_index(&#34;year&#34;, inplace=True)``&gt;&gt;&gt; df`         `name  age``year`              `2020    alice   20``2021      bob   30``2022  charlie   40``   ``df.stack() # 列转行-创建新dataframe``&gt;&gt;&gt;` `year`      `2020  name      alice`      `age          20``2021  name        bob`      `age          30``2022  name    charlie`      `age          40``   ``# unstack: 行转列``df.stack().unstack() # 行转列-还原为原来的效果
</code></pre><p>63、如何在pandas中使用crosstab函数进行数据透视操作</p>
<pre tabindex="0"><code>pd.crosstab(index, # 行`            `columns, # 列`            `values=None, # 聚合列`            `aggfunc=None, # 聚合函数`            `rownames=None, # 行-分组名称`            `colnames=None, # 列-分组名称`            `dropna=True, # 是否删除空值`            `normalize=False) # 是否标准化
</code></pre><p>64、在pandas中使用cut函数对数据进行离散化(分箱)</p>
<pre tabindex="0"><code>pd.cut(x=df[&#34;age&#34;], bins=10, right=True, labels=None)``# bins: 为整数表示分箱数量(等宽分)，为列表时表示切分点``# right: True-左开右闭``# labels: 分箱后显示的分箱名``# retbins=False, 是否返回分箱边界值
</code></pre><p>65、如何在pandas中使用qcut函数对数据进行等频分箱</p>
<pre tabindex="0"><code>qcut(x, # 待分箱的数据`     `q, # 等频分箱数量`     `labels=None, # 分箱后箱体名`     `retbins=False, # 是否返回分箱边界值`     `precision=3, # 分位数精度`     `duplicates=&#39;raise&#39; # 切分点重复如何处理`     `)
</code></pre><p>66、在pandas中使用interpolate函数进行数据插值操作</p>
<pre tabindex="0"><code>df.interpolate(method=&#39;liner&#39;, axis=0, limit=None, inplace=False)``# liner-线性插值
</code></pre><p>67、在pandas中使用bfill 和 ffill 函数进行数据填充操作</p>
<pre tabindex="0"><code>df.bfill() # 使用后值填充``df.ffill() # 使用前值填充
</code></pre><p>68、在pandas中使用正则表达式进行数据过滤操作</p>
<p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NzAyODM4NQ==&amp;mid=2247485198&amp;idx=1&amp;sn=69c501b9727f18d654fc3fecf06f2f64&amp;chksm=fc3d4240cb4acb563bd285ce223d997bd5797713abbac6f14ce3d3804172d02837bc3b86a428&amp;scene=21#wechat_redirect">【python 基础】re 正则表达式</a></p>
<pre tabindex="0"><code># pd.Series.str.contains(pat, case=True, flags=0, na=None, regex=True)``# pat: 字符类型 字符序列或者正则表达式``# case: 布尔类型 是否区分大小写``# flags: int类型 默认0 标志传递到re模块 比如flags=re.INGNORECASE 等价于 case=False``# na: 默认NaN 填写缺失值的值 可以随意指定``# regex: 布尔类型 默认True 假定pat为正则表达式 针对特殊字符需要设置regex=False``df = pd.DataFrame({&#34;name&#34;: [&#34;alice&#34;, &#34;bob&#34;, &#34;charlie&#34;, &#34;diana&#34;, &#34;emily&#34;],`                   `&#34;age&#34;: [10, 20, 30, 40, 50],`                   `&#34;email&#34;: [&#34;alice@qq.com&#34;, &#34;bob@163.com&#34;, &#34;charlie@yahoo.com&#34;, &#34;diana@gmail.com&#34;, &#34;emily@hotmail.com&#34;]})``&gt;&gt;&gt; df`      `name  age              email``0    alice   10       alice@qq.com``1      bob   20        bob@163.com``2  charlie   30  charlie@yahoo.com``3    diana   40    diana@gmail.com``4    emily   50  emily@hotmail.com``   ``df[df[&#34;email&#34;].str.contains(pat=&#34;gmail&#34;)]``&gt;&gt;&gt; ``    name  age            email``3  diana   40  diana@gmail.com``   ``df[df[&#34;email&#34;].str.contains(pat=&#34;gmail|qq&#34;, case=False)]``&gt;&gt;&gt; ``    name  age            email``0  alice   10     alice@qq.com``3  diana   40  diana@gmail.com
</code></pre><p>69、如何在pandas中使用diff函数进行时间序列处理</p>
<pre tabindex="0"><code># 使用场景：现有某个用户的操作日志，想知道上一次操作跟下一次操作的间隔时间是多少。``date_range = pd.date_range(&#39;2023-01-01&#39;, periods=5)``se = pd.Series(data=date_range)``&gt;&gt;&gt; se``0   2023-01-01``1   2023-01-02``2   2023-01-03``3   2023-01-04``4   2023-01-05``   ``se_diff = se.diff() # 不填数字表示一阶，填了数字表示多阶，递减``&gt;&gt;&gt; se_diff``0      NaT``1   1 days``2   1 days``3   1 days``4   1 days
</code></pre><p>70、在dataframe中使用dropna进行删除空值的操作</p>
<pre tabindex="0"><code>pd.DataFrame.dropna(axis=0, how=&#39;any&#39;, thresh=None, subset=None, inplace=True)``# subset: 用来判断是否删除的列``# axis: 0-删除行, 1-删除列``# how: any-一旦存在空值就删除, all-全为空时删除``# thresh: 0-1的浮点数，空值占比大于一定比例时删除``# inplace: 是否原地操作
</code></pre><p>71、如何在panda中使用join函数进行数据拼接操作</p>
<pre tabindex="0"><code># 类似于sql中的join，但不会自动合并相同列名的字段``# 只要两个表列名不同，不加任何参数就可以直接用。``# 如果两个表有重复的列名，需指定 lsuffix（左侧数据重列列使用的列名后缀）, rsuffix 参数。``# 参数的意义与 merge 方法基本相同。``   ``df1.join(df2, on=[&#34;col1&#34;, &#34;col2&#34;], how=&#39;inner&#39;)
</code></pre><p><img src="https://mmbiz.qpic.cn/mmbiz_png/phUvdvw2lot9RwMjBXxQxEic8dFea6rnKToZ0oSjlbGH3DZDDav6YaYn2fHDG4iaKMmpIqhyicqic6FWkY4NYT5dzQ/640?wx_fmt=png" alt=""></p>
<p>72、如何在pandas中使用get_dummies函数进行哑变量编码操作</p>
<pre tabindex="0"><code>df = pd.DataFrame({&#34;color&#34;: [&#34;red&#34;, &#34;blue&#34;, &#34;green&#34;, &#34;red&#34;, &#34;grey&#34;]})``&gt;&gt;&gt; df`   `color``0    red``1   blue``2  green``3    red``4   grey``   ``pd.get_dummies(df[&#39;color&#39;])``&gt;&gt;&gt; ``   blue  green  grey  red``0     0      0     0    1``1     1      0     0    0``2     0      1     0    0``3     0      0     0    1``4     0      0     1    0
</code></pre><p>73、如何将dataframe中的某一列转为int类型</p>
<pre tabindex="0"><code>df[&#39;col_name&#39;] = df[&#39;col_name&#39;].astype(np.int)
</code></pre><p>74、如何将dataframe中的某一列转为float类型</p>
<pre tabindex="0"><code># 方法1``df[&#39;col_name&#39;] = df[&#39;col_name&#39;].astype(np.float)``# 方法2``df[&#39;col_name&#39;] = df[&#39;col_name&#39;].map(lambda x: float(x))``   ``不管是转为int还是float，都需要把数据中的特殊字符(如：NA, NULL等)转为空值，再转为需要的类型
</code></pre><p>75、如何使用to_excel进行excel数据写入操作</p>
<pre tabindex="0"><code>df.to_excel(excel_writer=&#34;文件路径&#34;,`    `sheet_name=&#34;Sheet1&#34;, # sheet表名`    `)
</code></pre><p>76、如何使用to_json将数据保存为json文件</p>
<pre tabindex="0"><code>df.to_json(path_or_buf=&#34;df.json&#34;, orient=None)``# orient:``#     split: 将json文件转换为多个文件，每个文件包含dafaframe中的一行``#     records: 将json文件转换为一个列表，每个元素是dataframe中的一行``#     index: 将json文件转换为一个字典，键是列名，值是一行记录``#     columns: 将json文件转换为一个字典，键是列名，值是一列记录``#     values: 将json文件转换为一个二维数组，每行是dataframe的一行记录
</code></pre><p>77、如何在pandas中使用plot函数画出柱形图</p>
<pre tabindex="0"><code>import pandas as pd``import numpy as np``import matplotlib.pyplot as plt``   ``df = pd.DataFrame({&#34;name&#34;: [&#34;tom&#34;, &#34;jerry&#34;, &#34;mickey&#34;, &#34;minnie&#34;, &#34;donald&#34;],`        `&#34;age&#34;: [25, 23, 28, 27, 26],`        `&#34;score&#34;: [80, 90, 75, 85, 95]})``df.plot(kind=&#34;bar&#34;, x=&#34;name&#34;, y=&#39;score&#39;)``# plt.show() # jupyter需要执行plt.show才能在界面上显示图片
</code></pre><p>78、如何在pandas中使用plot函数画出折线图</p>
<pre tabindex="0"><code># 当设置的标签信息有中文时，一般要先做一些设置``plt.rcParams[&#39;font.sans-serif&#39;]=[&#39;SimHei&#39;] # 显示中文``plt.rcParams[&#39;axes.unicode_minus&#39;]=False # 取消使用unicode的负号``   ``plt.plot(df[&#34;col_x&#34;], df[&#34;col_y&#34;])``plt.title(&#34;图标题&#34;)``plt.xlabel(&#34;x轴名&#34;)``ply.ylabel(&#34;y轴名&#34;)``plt.show()
</code></pre><p>79、如何在pandas中使用plot函数画散点图</p>
<pre tabindex="0"><code>df.plot(kind=&#34;scatter&#34;, x=&#34;name&#34;, y=&#39;score&#39;)
</code></pre><p>80、如何在pandas中使用plot函数画出箱线图</p>
<pre tabindex="0"><code># 方法1``df.plot(kind=&#34;box&#34;, x=&#34;name&#34;, y=&#39;score&#39;)``# 方法2``df.plot.box() # 默认对所有数值列绘制箱线图
</code></pre><p><img src="https://mmbiz.qpic.cn/mmbiz_png/phUvdvw2lot9RwMjBXxQxEic8dFea6rnK6eO7MOA4IHpPQ6vjiatXzXkXdR04qK1KwvSoxYvBWeMroH6055l8rWQ/640?wx_fmt=png" alt=""></p>
<p>81、如何在pandas中使用plot函数画出面积图</p>
<pre tabindex="0"><code>pd.DataFrame.plot.area(x=None, y=None)``# 不传入x/y则是一个多列堆叠的面积图
</code></pre><p>82、如何在pandas中使用plot函数绘制饼图</p>
<pre tabindex="0"><code>df.plot(kind=&#39;pie&#39;, y=&#34;绘制饼图的列&#34;)
</code></pre><p>83、如何在pandas中对一列数据的正数和负数进行分组聚合操作</p>
<pre tabindex="0"><code>import pandas as pd``df = pd.DataFrame({&#34;val&#34;: [1, -2, 3, -4, 5]})``df[&#34;positive&#34;] = df[&#34;val&#34;] &gt; 0``df[&#34;negative&#34;] = df[&#34;val&#34;] &lt; 0``df_result = df.groupby(by=[&#34;positive&#34;, &#34;negative&#34;]).agg({&#34;val&#34;: &#34;sum&#34;})``df_result` `# 不知道意义在哪....
</code></pre><p>84、如何在pandas中实现两列的拼接</p>
<pre tabindex="0"><code>df[&#34;new&#34;] = df[&#34;col_1&#34;] + df[&#34;col_2&#34;]
</code></pre><p>85、如何对数据框中的字符串进行模糊匹配</p>
<pre tabindex="0"><code># pd.Series.str.contains(pat, case=True, flags=0, na=None, regex=True)``# pat: 字符类型 字符序列或者正则表达式``# case: 布尔类型 是否区分大小写``# flags: int类型 默认0 标志传递到re模块 比如flags=re.INGNORECASE 等价于 case=False``# na: 默认NaN 填写缺失值的值 可以随意指定``# regex: 布尔类型 默认True 假定pat为正则表达式 针对特殊字符需要设置regex=False
</code></pre><p>86、如何使用pandas处理文本数据</p>
<pre tabindex="0"><code># lower() / upper() 字母转小写、大写``# strip() 去除首尾空格``# split() 字符串切分``# contains() 判断字符串是否包含指定文本``# replace() 文本替换``# extract() 从字符串中提取指定的文本``df[&#39;col_new&#39;] = df[&#34;col&#34;].str.func()
</code></pre><p>87、如何在dataframe中找到重复的行</p>
<pre tabindex="0"><code>df.duplicated(subset=[&#34;col_1&#34;, &#34;col2&#34;])``# subset: 判断是否重复的字段``# axis=0,默认判断重复行
</code></pre><p>88、如何查看数的异常值</p>
<pre tabindex="0"><code># 通过数据描述信息，判断是否存在异常值``import pandas as pd``df.describe()``   ``# 通过箱线图，判断是否存在异常值``from matplotlib import pyplot as plt``plt.boxplot(df)` `# df可以是一个Series，也可以是一个DataFrame``# 当df是一个DataFrame时，建议选取处于同一数量级，不然画出来的图就很难判断
</code></pre><p>89、如何查找dataframe中的缺失值</p>
<pre tabindex="0"><code># 使用某一列判断，得到存在空值的行``df[df[&#39;col&#39;].isnull()]``   ``# 判断整个dataframe每个字段的数量``df.isnull().sum()``   ``# info可以获取数据集信息``df.info()
</code></pre><p>90、如何在dataframe中获取某一列的值只出现一次的所有行</p>
<pre tabindex="0"><code>se_value_counts = df[&#39;col&#39;].value_counts()``df[df[&#34;col&#34;].isin(se_value_counts[se_value_counts==1].index)]
</code></pre><p>91、如何在pandas中求相邻元素的差异</p>
<pre tabindex="0"><code>df[&#39;col&#39;].diff()` `# 当col字段是时间时，求的是前后两条记录的时间差``# 当col字段是数值时，求的是间隔元素的差值
</code></pre><p>92、如何将dataframe中的某一列中包含的字符串进行拆分</p>
<pre tabindex="0"><code># 新字段是一个列表，并且没找到切分符号会返回空值``df[&#39;col_new&#39;] = df[&#39;col&#39;].str.split(&#34;_&#34;)``   ``# 取切分后的第一个值``df[&#34;col_new&#34;] = df[&#34;col&#34;].map(lambda x: str(x).split(&#34;_&#34;)[0])
</code></pre><p>93、如何使用pandas 对某一列数据进行md5加密</p>
<pre tabindex="0"><code># 联合建模时，对姓名、手机号、身份证等敏感信息进行加密``import hashlib``df[&#39;col_md5&#39;] = df[&#34;col&#34;].map(lambda x: hashlib.md5(x).hexdigest())
</code></pre><p>94、如何在pandas中使用groupby和agg进行分组聚合</p>
<pre tabindex="0"><code>df.groupby(by=[&#34;col_1&#34;, &#34;col_2&#34;]).agg({&#34;score&#34;: &#34;sum&#34;, &#34;age&#34;: &#34;mean&#34;})
</code></pre><p>95、如何在dataframe中使用cumsum函数进行累计计算</p>
<pre tabindex="0"><code># 整个dataframe横向或纵向求和, 0-横向,1-纵向``df.cumsum(axis=1)
</code></pre><p>96、如何将dataframe根据某一列的值进行过滤</p>
<pre tabindex="0"><code># 筛选出年龄 大于 30 的 男性``df[(df[&#39;age&#39;]&gt;30) &amp; df[&#39;gender&#39;]==&#39;male&#39;]
</code></pre><p>97、如何使用pandas中的值计算出新的一列</p>
<pre tabindex="0"><code>df[&#39;new&#39;] = 0.4 * df[&#34;col&#34;] + 0.6*100
</code></pre><p>98、如何为dataframe的每个元素使用一个自定义函数</p>
<pre tabindex="0"><code>def test(x)`    `return x+1``df_new = df.apply(test)
</code></pre><p>99、如何使用pandas对数据进行预处理</p>
<pre tabindex="0"><code># 读取数据``df = pd.read_csv(datapath) # pd.read_excel(datapath, sheet_name)``# 描述信息``df.describe()``# 数据详情``df.info()``# 类型转换``df[&#34;col&#34;] = df[&#34;col&#34;].astype(np.int)``# 删除空值``df.dropna()``# 删除重复值``df.drop_duplicates()``# 填充空值``df.fillna()
</code></pre><p>100、如何从一个csv文件中读取数据，将其中的数值数据进行聚合，并计算每个聚合后的组的中位数</p>
<pre tabindex="0"><code># 读取数据``df = pd.read_csv(datapath, encoding=&#39;utf-8&#39;)``# 删除重复值``df.drop_duplicates(inplace=True)``# 删除空值``df.dropna(subset=[...], inplace=True, how=&#39;any&#39;)``# 分组聚合``df.groupby(by=[&#34;col_1&#34;, &#34;col_2&#34;]).agg({&#34;col_cal&#34;: &#34;median&#34;})
</code></pre><p>本文转自 <a href="https://mp.weixin.qq.com/s/ER3s5yjMwMzQqiEr8YwYJQ">https://mp.weixin.qq.com/s/ER3s5yjMwMzQqiEr8YwYJQ</a>，如有侵权，请联系删除。</p>

    </div>

    

    

    <div class="container-prevnext">
    <div><a href="https://richfan.site/posts/%E7%A8%8B%E6%8A%80/git/">← Git 的使用</a></div>
    <div><a href="https://richfan.site/posts/%E7%A8%8B%E6%8A%80/emoji/">emoji  →</a></div>
</div>
    
    

    
</div>

        </div>
        <div id="footer"><div class="container-footer">
    
    <a href="//beian.miit.gov.cn" target="_blank">
        
        京ICP备2022007001号
        
    </a>
    <a id="s" href="/secrets">&nbsp;</a>
    
</div></div>
    </body>
</html>
